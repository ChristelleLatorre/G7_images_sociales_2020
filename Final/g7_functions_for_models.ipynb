{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on: Thu Wed 15 09:44:36 2020\n",
    "\n",
    "Group 7\n",
    "<br>\n",
    "@authors: E.G., C.L., P.S.B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of train test files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeatGuru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs_seatguru_type(df_seat_annot: pd.DataFrame, project_path: str, data_path: str:,\n",
    "                              aircraft_types: list, view: str, man: str):\n",
    "    \n",
    "    \"\"\"Creates one directory per aircraft type with all corresponding images.\n",
    "    \n",
    "    Parameters:\n",
    "        df_seat_annot: Seatguru annotated DataFrame, containing the 'view' label\n",
    "        project_path: path to the project directory\n",
    "        data_path: path to the data directory\n",
    "        aircraft_types: list of aircraft types, e.g. ['A320', 'A330']\n",
    "        view: 'Int' or 'Ext'\n",
    "        man: 'Airbus' or 'Boeing'\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get Seatguru 'view' labels, and get a list of all images of required view (Interior or Exterior)\n",
    "    ind_int = df_seat_annot[df_seat_annot['view'] == view]['name'].tolist()\n",
    "    imgs_list = os.listdir(project_path + data_path)\n",
    "    imgs_man = [img for img in imgs_list if man in img]\n",
    "    crea_path = project_path + 'G7_SEATGURU/' + view + '/' + man + '/'\n",
    "    \n",
    "    # For each aircraft type, create and fill a directory\n",
    "    for typ in aircraft_types:\n",
    "        typ_imgs = [[project_path + data_path + img, img] for img in imgs_list\n",
    "                    if (typ in img and img in ind_int)]\n",
    "        shutil.rmtree(crea_path + typ, ignore_errors = True)\n",
    "        os.makedirs(crea_path + typ)\n",
    "        print(crea_path + typ)\n",
    "\n",
    "        for img in typ_imgs:\n",
    "            copyfile(img[0], crea_path + typ + '/' + img[1])\n",
    "        \n",
    "        print(f'{typ}: {len(os.listdir(crea_path + typ))} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_seatguru_type(new_paths: list, path: str, aircraft_types: list, split_limit: float=.7, \n",
    "                                   s: int=8, ext: str='.jpg'):\n",
    "    \n",
    "    \"\"\"Splits Seatguru images into train and test sets, to be used for aircraft types prediction.\n",
    "    \n",
    "    Parameters:\n",
    "        new_paths: paths to train and test\n",
    "        path: where to get the reference dataset\n",
    "        aircraft_types: list of aircraft types, e.g. ['A320', 'A330'] \n",
    "        split_limit: % of images to use as train set\n",
    "        s: random seed\n",
    "        ext: images extension\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Train-test split each aircraft type set, create and fill train and test folders  \n",
    "    for typ in aircraft_types:\n",
    "        shutil.rmtree(new_paths[0] + '/' + typ, ignore_errors=True)\n",
    "        os.makedirs(new_paths[0] + '/' + typ)\n",
    "        shutil.rmtree(new_paths[1] + '/' + typ, ignore_errors=True)\n",
    "        os.makedirs(new_paths[1] + '/' + typ)\n",
    "        \n",
    "        imgs = os.listdir(path + typ)\n",
    "        imgs = [img for img in imgs if pic[-4:] == ext]\n",
    "        random.seed(a=s)\n",
    "        random.shuffle(imgs)\n",
    "        \n",
    "        for pict in imgs[:int(split_limit * len(imgs))]:\n",
    "            copyfile(path + typ + '/' + img, new_paths[0] + '/' + typ + '/' + img)\n",
    "   \n",
    "        for pict in imgs[int(split_limit * len(imgs)):]:\n",
    "            copyfile(path + typ + '/' + img, new_paths[1] + '/' + typ + '/' + img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_seatguru_man(new_paths: list, path: str, list_airbus: list, list_boeing: list,\n",
    "                                  split_limit: float=.7, s: int=8):\n",
    "    \n",
    "    \"\"\"Splits Seatguru images into train and test sets, to be used for aircraft manufacturers prediction.\n",
    "\n",
    "    Parameters:\n",
    "        new_paths: paths to train and test\n",
    "        path: where to get the reference dataset\n",
    "        list_airbus: list of Airbus aircraft types, e.g. ['A320', 'A330'] \n",
    "        list_boeing: list of Boeing aircraft types, e.g. ['737', '747'] \n",
    "        split_limit: % of images to use as train set\n",
    "        s: random seed\n",
    "\n",
    "    \"\"\"\n",
    "  \n",
    "    list_planes = [list_airbus, list_boeing]\n",
    "    \n",
    "    for imgs in list_planes:\n",
    "        if imgs == list_airbus:\n",
    "            man = 'Airbus'\n",
    "        if imgs == list_boeing:\n",
    "            man = 'Boeing'\n",
    "        \n",
    "        shutil.rmtree(new_paths[0] + '/' + man, ignore_errors=True)\n",
    "        os.makedirs(new_paths[0] + '/' + man)\n",
    "        \n",
    "        shutil.rmtree(new_paths[1] + '/' + man, ignore_errors=True)\n",
    "        os.makedirs(new_paths[1]+ '/' + man)\n",
    "        \n",
    "        random.seed(a=s)\n",
    "        random.shuffle(imgs)\n",
    "        \n",
    "        print(new_paths[0] + '/' + man)\n",
    "\n",
    "        for img in imgs[:int(split_limit * len(imgs))]:\n",
    "            copyfile(path + pict, new_paths[0] + '/' + man + '/' + img)\n",
    "        for img in imgs[int(split_limit * len(imgs)):]:\n",
    "            copyfile(path + pict, new_paths[1] + '/' + man + '/' + img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airliners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs_airliners(list_planes: list, man: str, split_limit: float=.7, s: int):\n",
    "    \n",
    "    for plane in list_planes:\n",
    "        os.makedirs(new_paths[0] + '/' + plane)\n",
    "        os.makedirs(new_paths[1] + '/' + plane)\n",
    "        \n",
    "        picts = os.listdir(Airliners_path + '/' + man + '/' + plane)\n",
    "        random.seed(a=s)\n",
    "        random.shuffle(picts)\n",
    "        \n",
    "        for pict in picts[:int(split_limit * len(picts))]:\n",
    "            copyfile(Airliners_path + '/' + man + '/' + plane + '/' + pict, \n",
    "                     new_paths[0] + '/' + plane + '/' + pict)\n",
    "            \n",
    "        for pict in picts[int(split_limit * len(picts)):]:\n",
    "            copyfile(Airliners_path + '/' + man + '/' + plane + '/' + pict, \n",
    "                     new_paths[1] + '/' + plane + '/' + pict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_train_test_airliners(Airliners_path: str, new_paths: list, \n",
    "                             airbus_planes: list=['A320', 'A321', 'A350', 'A330'], \n",
    "                             boeing_planes: list=['737', '747', '757', '777'], \n",
    "                             split_limit: float=.7, s:int = 8):\n",
    "    \n",
    "    for i in range(2): \n",
    "        os.makedirs(new_paths[i], exist_ok=True)\n",
    "        for fd in os.listdir(new_paths[i]):\n",
    "            shutil.rmtree(new_paths[i] + '/' + fd, ignore_errors=True)\n",
    "            \n",
    "    create_dirs_airliners(airbus_planes, 'Airbus', split_limit, s)\n",
    "    create_dirs_airliners(boeing_planes, 'Boeing', split_limit, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A v√©rifier\n",
    "def split_train_test_hack(new_paths, path, airbus_planes=['A320', 'A321', 'A350', 'A380'],\n",
    "                          split_limit: float=.7, s: int=8, ext: str='.jpg'):\n",
    "   \n",
    "    for plane in airbus_planes:\n",
    "\n",
    "        shutil.rmtree(new_paths[0] + '/' + plane, ignore_errors=True)\n",
    "        os.makedirs(new_paths[0] + '/' + plane)\n",
    "        shutil.rmtree(new_paths[1] + '/' + plane, ignore_errors=True)\n",
    "        os.makedirs(new_paths[1] + '/' + plane)\n",
    "        \n",
    "        picts = os.listdir(path + '/' + plane)\n",
    "        picts = [pic for pic in picts if pic[-4:] == ext]\n",
    "        random.seed(a = s)\n",
    "        random.shuffle(picts)\n",
    "        \n",
    "        for pict in picts[:int(split_limit*len(picts))]:\n",
    "            copyfile(path + plane + '/' + pict, new_paths[0] + '/' + plane + '/' + pict)\n",
    "        for pict in picts[int(split_limit*len(picts)):]:\n",
    "            copyfile(path + plane + '/' + pict, new_paths[1] + '/' + plane + '/' + pict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_classes(path_mod, mod_name, train_generator, model):\n",
    "    \n",
    "    shutil.rmtree(path_mod + mod_name, ignore_errors = True)\n",
    "    os.makedirs(path_mod + mod_name)\n",
    "    label_map = (train_generator.class_indices)\n",
    "    with open(path_mod + mod_name + '/' + 'model_' + mod_name + '.pkl', \"wb\") as f:\n",
    "        pickle.dump(label_map, f)\n",
    "    model.save(path_mod + mod_name + '/' + 'model_'+ mod_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files_model(path_mod, mod_name):\n",
    "    model = load_model(path_mod + mod_name + '/' + 'model_'+ mod_name + '.h5')\n",
    "    with open(path_mod + mod_name + '/' + 'model_' + mod_name + '.pkl', \"rb\") as f:\n",
    "        dic_class = pickle.load(f)\n",
    "    return model, dic_class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
