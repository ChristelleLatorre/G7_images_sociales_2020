{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on Fri Jan 10 11:06:30 2020\n",
    "<br>\n",
    "Group 7\n",
    "<br>\n",
    "@author: E.G.\n",
    "\n",
    "<h1>Group 7 - Images sociales<span class=\"tocSkip\"></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Environment\" data-toc-modified-id=\"Environment-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Environment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Libraries\" data-toc-modified-id=\"Libraries-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Libraries</a></span></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Parameters</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Functions</a></span></li></ul></li><li><span><a href=\"#Pre-processing\" data-toc-modified-id=\"Pre-processing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Pre-processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-test-split-and-read-images\" data-toc-modified-id=\"Train-test-split-and-read-images-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Train-test split and read images</a></span></li></ul></li><li><span><a href=\"#Build,-save,-and-train-model\" data-toc-modified-id=\"Build,-save,-and-train-model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Build, save, and train model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook trains a model to predict Airbus aircraft types on images representing an aircraft interior. The images used for training come from Hackathon data (\"clean\" images of Airbus aircraft interiors).\n",
    "\n",
    "**Pre-processing**<span class=\"tocSkip\"></span><br>\n",
    "By reading and filtering the CSV file that contains the labels (Int, Ext, Ext-Int, Meal), we get the list of Interior labelled images. Then, the images are copied to directories (one per desired aircraft type), and split into train and test sets. If the data augmentation option is set to `True`, the train set will be enriched with new images (obtained by cropping / (de)zooming / rotating / flipping existing images).\n",
    "\n",
    "**Model**<span class=\"tocSkip\"></span><br>\n",
    "We get weights from VGG16 pre-trained model, and add some layers (Conv2D, ReLU, MaxPooling2D, Flatten, and Dense) to predict the target classes (e.g.: 3 classes could be A320, A350, and A380).\n",
    "\n",
    "**Out**<span class=\"tocSkip\"></span><br>\n",
    "After training, a folder is created in `Models` repository, containing the model in `h5` format, along with the corresponding labels stored in a `pickle` dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "To ensure a proper functioning of this code file, `python 3.6` or later version is required.\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T15:19:11.728311Z",
     "start_time": "2020-01-09T15:19:06.196795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, InputLayer, ReLU, AveragePooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "from shutil import copyfile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras 2.3.1\n",
      "tensorflow 1.13.1\n",
      "PIL 6.2.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p keras,tensorflow,PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = './../'\n",
    "seatguru_path = './../All Data/ANALYSE IMAGE/IMG SEATGURU/'\n",
    "hackathon_path = './../Inputs Hackathon/'\n",
    "new_path_train = './../Split_data/Hackathon/Int/data_train'\n",
    "new_path_val = './../Split_data/Hackathon/Int/data_val'\n",
    "new_paths = [new_path_train, new_path_val]\n",
    "model_name = 'Int_Airbus_Hackathon'\n",
    "\n",
    "# Images parameters\n",
    "size = (224, 224)\n",
    "greys = False\n",
    "apply_data_augmentation = True\n",
    "\n",
    "# Classes to predict\n",
    "airbus_planes = ['A320', 'A350', 'A380']\n",
    "nb_types = len(airbus_planes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run g7_functions_for_models.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "## Train-test split and read images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_test_hack(new_paths, hackathon_path,\n",
    "                      airbus_planes=airbus_planes, split_limit=.7, s=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T15:26:28.959798Z",
     "start_time": "2020-01-09T15:26:19.480789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 618 images belonging to 3 classes.\n",
      "Found 267 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image data generator\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = train_datagen.flow_from_directory(new_paths[0],\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "\n",
    "test_generator = train_datagen.flow_from_directory(new_paths[1],\n",
    "                                                   target_size=(224, 224),\n",
    "                                                   color_mode='rgb',\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build, save, and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T09:22:00.420098Z",
     "start_time": "2020-01-10T09:21:59.487724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 17,282,884\n",
      "Trainable params: 2,564,100\n",
      "Non-trainable params: 14,718,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the base pre-trained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False,\n",
    "                   input_shape=(size[0], size[1], 1 if greys else 3))\n",
    "x = base_model.output\n",
    "\n",
    "# Add layers\n",
    "x = Conv2D(256, kernel_size=(3, 3))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(256, kernel_size=(3, 3))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)  # vector\n",
    "\n",
    "x = Dense(1024)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Dense(512)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "# Last layer used to predict our classes\n",
    "# Dense has the same number of neurons as the number of classes to predict\n",
    "predictions = Dense(nb_types, activation='softmax')(x)\n",
    "\n",
    "# Model to be trained\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Don't retrain pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model (should be done after setting layers to non-trainable)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce learning rate when a metric has stopped improving\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy',  # chosen metric\n",
    "                              patience=2,  # number of epochs\n",
    "                              verbose=1,\n",
    "                              factor=0.5,\n",
    "                              min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T09:46:07.626778Z",
     "start_time": "2020-01-10T09:27:13.063490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - ETA: 16:00 - loss: 0.2860 - accuracy: 0.875 - ETA: 14:17 - loss: 0.2802 - accuracy: 0.906 - ETA: 13:26 - loss: 0.2479 - accuracy: 0.916 - ETA: 12:02 - loss: 0.2400 - accuracy: 0.914 - ETA: 11:01 - loss: 0.2803 - accuracy: 0.900 - ETA: 10:05 - loss: 0.2605 - accuracy: 0.911 - ETA: 9:13 - loss: 0.2924 - accuracy: 0.901 - ETA: 8:34 - loss: 0.2965 - accuracy: 0.90 - ETA: 7:55 - loss: 0.2885 - accuracy: 0.90 - ETA: 7:18 - loss: 0.2650 - accuracy: 0.91 - ETA: 6:44 - loss: 0.2436 - accuracy: 0.92 - ETA: 6:12 - loss: 0.2380 - accuracy: 0.91 - ETA: 5:41 - loss: 0.2270 - accuracy: 0.92 - ETA: 5:11 - loss: 0.2269 - accuracy: 0.92 - ETA: 4:42 - loss: 0.2311 - accuracy: 0.92 - ETA: 4:12 - loss: 0.2284 - accuracy: 0.91 - ETA: 3:42 - loss: 0.2575 - accuracy: 0.90 - ETA: 3:13 - loss: 0.2652 - accuracy: 0.90 - ETA: 2:44 - loss: 0.2748 - accuracy: 0.90 - ETA: 2:15 - loss: 0.2760 - accuracy: 0.90 - ETA: 1:47 - loss: 0.2877 - accuracy: 0.90 - ETA: 1:20 - loss: 0.2836 - accuracy: 0.90 - ETA: 53s - loss: 0.2897 - accuracy: 0.9008 - ETA: 26s - loss: 0.2984 - accuracy: 0.897 - 911s 36s/step - loss: 0.2986 - accuracy: 0.8965 - val_loss: 2.7400 - val_accuracy: 0.5710\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - ETA: 14:12 - loss: 0.2641 - accuracy: 0.906 - ETA: 13:20 - loss: 0.1899 - accuracy: 0.921 - ETA: 12:37 - loss: 0.1596 - accuracy: 0.937 - ETA: 11:45 - loss: 0.1699 - accuracy: 0.937 - ETA: 10:48 - loss: 0.1599 - accuracy: 0.937 - ETA: 10:00 - loss: 0.1399 - accuracy: 0.942 - ETA: 9:16 - loss: 0.1663 - accuracy: 0.933 - ETA: 8:37 - loss: 0.1550 - accuracy: 0.93 - ETA: 8:01 - loss: 0.1699 - accuracy: 0.93 - ETA: 7:27 - loss: 0.1676 - accuracy: 0.92 - ETA: 6:54 - loss: 0.1666 - accuracy: 0.92 - ETA: 6:22 - loss: 0.1760 - accuracy: 0.92 - ETA: 5:51 - loss: 0.1706 - accuracy: 0.93 - ETA: 5:15 - loss: 0.1633 - accuracy: 0.93 - ETA: 4:45 - loss: 0.1604 - accuracy: 0.93 - ETA: 4:16 - loss: 0.2048 - accuracy: 0.92 - ETA: 3:46 - loss: 0.1963 - accuracy: 0.92 - ETA: 3:17 - loss: 0.1915 - accuracy: 0.93 - ETA: 2:48 - loss: 0.1868 - accuracy: 0.93 - ETA: 2:19 - loss: 0.1830 - accuracy: 0.93 - ETA: 1:51 - loss: 0.1924 - accuracy: 0.93 - ETA: 1:22 - loss: 0.2036 - accuracy: 0.92 - ETA: 54s - loss: 0.2033 - accuracy: 0.9258 - ETA: 27s - loss: 0.2005 - accuracy: 0.925 - 918s 37s/step - loss: 0.2069 - accuracy: 0.9230 - val_loss: 2.1954 - val_accuracy: 0.4784\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - ETA: 12:14 - loss: 0.6161 - accuracy: 0.812 - ETA: 12:23 - loss: 0.6030 - accuracy: 0.859 - ETA: 12:00 - loss: 0.5668 - accuracy: 0.854 - ETA: 11:15 - loss: 0.5504 - accuracy: 0.843 - ETA: 10:32 - loss: 0.4478 - accuracy: 0.875 - ETA: 9:54 - loss: 0.3944 - accuracy: 0.885 - ETA: 9:12 - loss: 0.3616 - accuracy: 0.89 - ETA: 8:27 - loss: 0.3479 - accuracy: 0.89 - ETA: 7:53 - loss: 0.3237 - accuracy: 0.90 - ETA: 7:16 - loss: 0.3145 - accuracy: 0.90 - ETA: 6:41 - loss: 0.2899 - accuracy: 0.91 - ETA: 6:09 - loss: 0.2828 - accuracy: 0.91 - ETA: 5:37 - loss: 0.2894 - accuracy: 0.91 - ETA: 5:07 - loss: 0.2759 - accuracy: 0.91 - ETA: 4:38 - loss: 0.2626 - accuracy: 0.92 - ETA: 4:10 - loss: 0.2579 - accuracy: 0.92 - ETA: 3:38 - loss: 0.2704 - accuracy: 0.91 - ETA: 3:10 - loss: 0.2726 - accuracy: 0.91 - ETA: 2:38 - loss: 0.2779 - accuracy: 0.91 - ETA: 2:09 - loss: 0.2812 - accuracy: 0.90 - ETA: 1:41 - loss: 0.2872 - accuracy: 0.91 - ETA: 1:14 - loss: 0.2790 - accuracy: 0.91 - ETA: 48s - loss: 0.2731 - accuracy: 0.9162 - ETA: 23s - loss: 0.2773 - accuracy: 0.913 - 729s 29s/step - loss: 0.2777 - accuracy: 0.9116 - val_loss: 8.4868 - val_accuracy: 0.3735\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - ETA: 6:38 - loss: 0.2004 - accuracy: 0.93 - ETA: 6:25 - loss: 0.2052 - accuracy: 0.92 - ETA: 6:24 - loss: 0.1887 - accuracy: 0.92 - ETA: 6:11 - loss: 0.1514 - accuracy: 0.94 - ETA: 5:51 - loss: 0.1743 - accuracy: 0.93 - ETA: 5:30 - loss: 0.1516 - accuracy: 0.94 - ETA: 5:12 - loss: 0.1444 - accuracy: 0.94 - ETA: 4:50 - loss: 0.1316 - accuracy: 0.94 - ETA: 4:36 - loss: 0.1253 - accuracy: 0.95 - ETA: 4:24 - loss: 0.1146 - accuracy: 0.95 - ETA: 4:13 - loss: 0.1062 - accuracy: 0.96 - ETA: 4:05 - loss: 0.1096 - accuracy: 0.96 - ETA: 3:55 - loss: 0.1024 - accuracy: 0.96 - ETA: 3:41 - loss: 0.1101 - accuracy: 0.96 - ETA: 3:26 - loss: 0.1120 - accuracy: 0.95 - ETA: 3:09 - loss: 0.1114 - accuracy: 0.95 - ETA: 2:51 - loss: 0.1192 - accuracy: 0.95 - ETA: 2:29 - loss: 0.1179 - accuracy: 0.95 - ETA: 2:09 - loss: 0.1142 - accuracy: 0.95 - ETA: 1:48 - loss: 0.1106 - accuracy: 0.95 - ETA: 1:27 - loss: 0.1088 - accuracy: 0.95 - ETA: 1:05 - loss: 0.1107 - accuracy: 0.95 - ETA: 44s - loss: 0.1144 - accuracy: 0.9588 - ETA: 22s - loss: 0.1118 - accuracy: 0.959 - 793s 32s/step - loss: 0.1103 - accuracy: 0.9609 - val_loss: 6.4358 - val_accuracy: 0.5556\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - ETA: 10:55 - loss: 0.0761 - accuracy: 0.968 - ETA: 10:56 - loss: 0.0502 - accuracy: 0.984 - ETA: 10:35 - loss: 0.0395 - accuracy: 0.989 - ETA: 10:14 - loss: 0.0384 - accuracy: 0.992 - ETA: 9:51 - loss: 0.0327 - accuracy: 0.993 - ETA: 9:21 - loss: 0.0322 - accuracy: 0.99 - ETA: 8:46 - loss: 0.0308 - accuracy: 0.99 - ETA: 8:12 - loss: 0.0279 - accuracy: 0.99 - ETA: 7:36 - loss: 0.0265 - accuracy: 0.99 - ETA: 7:02 - loss: 0.0279 - accuracy: 0.99 - ETA: 6:29 - loss: 0.0260 - accuracy: 0.99 - ETA: 5:58 - loss: 0.0258 - accuracy: 0.99 - ETA: 5:27 - loss: 0.0240 - accuracy: 0.99 - ETA: 4:59 - loss: 0.0231 - accuracy: 0.99 - ETA: 4:24 - loss: 0.0220 - accuracy: 0.99 - ETA: 3:58 - loss: 0.0208 - accuracy: 0.99 - ETA: 3:32 - loss: 0.0198 - accuracy: 0.99 - ETA: 3:06 - loss: 0.0206 - accuracy: 0.99 - ETA: 2:40 - loss: 0.0211 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0301 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0296 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0299 - accuracy: 0.99 - ETA: 53s - loss: 0.0424 - accuracy: 0.9905 - ETA: 26s - loss: 0.0407 - accuracy: 0.990 - 899s 36s/step - loss: 0.0419 - accuracy: 0.9899 - val_loss: 5.4380 - val_accuracy: 0.6574\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - ETA: 11:01 - loss: 0.0333 - accuracy: 1.000 - ETA: 10:42 - loss: 0.0345 - accuracy: 1.000 - ETA: 10:01 - loss: 0.0277 - accuracy: 1.000 - ETA: 9:21 - loss: 0.0284 - accuracy: 0.992 - ETA: 9:00 - loss: 0.0237 - accuracy: 0.99 - ETA: 8:16 - loss: 0.0216 - accuracy: 0.99 - ETA: 7:54 - loss: 0.0191 - accuracy: 0.99 - ETA: 7:29 - loss: 0.0197 - accuracy: 0.99 - ETA: 7:08 - loss: 0.0185 - accuracy: 0.99 - ETA: 6:44 - loss: 0.0169 - accuracy: 0.99 - ETA: 6:16 - loss: 0.0156 - accuracy: 0.99 - ETA: 5:50 - loss: 0.0144 - accuracy: 0.99 - ETA: 5:22 - loss: 0.0138 - accuracy: 0.99 - ETA: 4:56 - loss: 0.0131 - accuracy: 0.99 - ETA: 4:29 - loss: 0.0131 - accuracy: 0.99 - ETA: 4:02 - loss: 0.0216 - accuracy: 0.99 - ETA: 3:34 - loss: 0.0279 - accuracy: 0.99 - ETA: 3:07 - loss: 0.0269 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0264 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0274 - accuracy: 0.99 - ETA: 1:47 - loss: 0.0266 - accuracy: 0.99 - ETA: 1:20 - loss: 0.0299 - accuracy: 0.98 - ETA: 53s - loss: 0.0315 - accuracy: 0.9890 - ETA: 26s - loss: 0.0303 - accuracy: 0.989 - 920s 37s/step - loss: 0.0309 - accuracy: 0.9886 - val_loss: 1.9847 - val_accuracy: 0.5309\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - ETA: 11:17 - loss: 0.0759 - accuracy: 0.968 - ETA: 10:53 - loss: 0.1190 - accuracy: 0.953 - ETA: 10:24 - loss: 0.1503 - accuracy: 0.947 - ETA: 9:41 - loss: 0.1197 - accuracy: 0.960 - ETA: 9:06 - loss: 0.0982 - accuracy: 0.96 - ETA: 8:38 - loss: 0.1003 - accuracy: 0.96 - ETA: 8:12 - loss: 0.0989 - accuracy: 0.96 - ETA: 7:50 - loss: 0.1326 - accuracy: 0.96 - ETA: 7:27 - loss: 0.1236 - accuracy: 0.96 - ETA: 7:01 - loss: 0.1131 - accuracy: 0.96 - ETA: 6:30 - loss: 0.1030 - accuracy: 0.97 - ETA: 5:53 - loss: 0.0957 - accuracy: 0.97 - ETA: 5:23 - loss: 0.0889 - accuracy: 0.97 - ETA: 4:56 - loss: 0.0832 - accuracy: 0.97 - ETA: 4:29 - loss: 0.0778 - accuracy: 0.97 - ETA: 4:02 - loss: 0.0732 - accuracy: 0.98 - ETA: 3:34 - loss: 0.0692 - accuracy: 0.98 - ETA: 3:06 - loss: 0.0662 - accuracy: 0.98 - ETA: 2:39 - loss: 0.0633 - accuracy: 0.98 - ETA: 2:12 - loss: 0.0603 - accuracy: 0.98 - ETA: 1:46 - loss: 0.0664 - accuracy: 0.98 - ETA: 1:19 - loss: 0.0641 - accuracy: 0.98 - ETA: 52s - loss: 0.0622 - accuracy: 0.9835 - ETA: 26s - loss: 0.0598 - accuracy: 0.984 - 912s 36s/step - loss: 0.0577 - accuracy: 0.9848 - val_loss: 4.2851 - val_accuracy: 0.6944\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - ETA: 11:56 - loss: 0.0473 - accuracy: 0.968 - ETA: 11:26 - loss: 0.0324 - accuracy: 0.984 - ETA: 10:47 - loss: 0.0708 - accuracy: 0.968 - ETA: 10:02 - loss: 0.0558 - accuracy: 0.976 - ETA: 9:17 - loss: 0.0537 - accuracy: 0.981 - ETA: 8:39 - loss: 0.0492 - accuracy: 0.98 - ETA: 8:17 - loss: 0.0435 - accuracy: 0.98 - ETA: 7:52 - loss: 0.0385 - accuracy: 0.98 - ETA: 7:25 - loss: 0.0343 - accuracy: 0.98 - ETA: 7:00 - loss: 0.0406 - accuracy: 0.98 - ETA: 6:34 - loss: 0.0457 - accuracy: 0.98 - ETA: 6:04 - loss: 0.0420 - accuracy: 0.98 - ETA: 5:33 - loss: 0.0389 - accuracy: 0.98 - ETA: 5:03 - loss: 0.0375 - accuracy: 0.98 - ETA: 4:33 - loss: 0.0350 - accuracy: 0.98 - ETA: 4:05 - loss: 0.0339 - accuracy: 0.99 - ETA: 3:37 - loss: 0.0320 - accuracy: 0.99 - ETA: 3:10 - loss: 0.0305 - accuracy: 0.99 - ETA: 2:42 - loss: 0.0293 - accuracy: 0.99 - ETA: 2:15 - loss: 0.0288 - accuracy: 0.99 - ETA: 1:48 - loss: 0.0275 - accuracy: 0.99 - ETA: 1:21 - loss: 0.0288 - accuracy: 0.99 - ETA: 53s - loss: 0.0405 - accuracy: 0.9905 - ETA: 26s - loss: 0.0426 - accuracy: 0.989 - 908s 36s/step - loss: 0.0415 - accuracy: 0.9900 - val_loss: 0.0919 - val_accuracy: 0.6451\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - ETA: 9:52 - loss: 0.0037 - accuracy: 1.00 - ETA: 10:35 - loss: 0.0035 - accuracy: 1.000 - ETA: 10:14 - loss: 0.0123 - accuracy: 1.000 - ETA: 9:29 - loss: 0.0146 - accuracy: 1.000 - ETA: 8:25 - loss: 0.0458 - accuracy: 0.99 - ETA: 7:55 - loss: 0.0384 - accuracy: 0.99 - ETA: 7:28 - loss: 0.0582 - accuracy: 0.98 - ETA: 7:09 - loss: 0.0620 - accuracy: 0.97 - ETA: 6:45 - loss: 0.0560 - accuracy: 0.98 - ETA: 6:24 - loss: 0.0532 - accuracy: 0.98 - ETA: 6:00 - loss: 0.0489 - accuracy: 0.98 - ETA: 5:36 - loss: 0.0451 - accuracy: 0.98 - ETA: 5:10 - loss: 0.0437 - accuracy: 0.98 - ETA: 4:43 - loss: 0.0413 - accuracy: 0.98 - ETA: 4:17 - loss: 0.0388 - accuracy: 0.98 - ETA: 3:47 - loss: 0.0367 - accuracy: 0.98 - ETA: 3:22 - loss: 0.0430 - accuracy: 0.98 - ETA: 2:57 - loss: 0.0410 - accuracy: 0.98 - ETA: 2:31 - loss: 0.0389 - accuracy: 0.98 - ETA: 2:06 - loss: 0.0373 - accuracy: 0.98 - ETA: 1:41 - loss: 0.0356 - accuracy: 0.98 - ETA: 1:16 - loss: 0.0341 - accuracy: 0.98 - ETA: 50s - loss: 0.0331 - accuracy: 0.9903 - ETA: 25s - loss: 0.0319 - accuracy: 0.990 - 857s 34s/step - loss: 0.0309 - accuracy: 0.9911 - val_loss: 3.9455 - val_accuracy: 0.6481\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - ETA: 11:04 - loss: 0.0234 - accuracy: 1.000 - ETA: 10:57 - loss: 0.0230 - accuracy: 1.000 - ETA: 10:32 - loss: 0.0157 - accuracy: 1.000 - ETA: 9:46 - loss: 0.0122 - accuracy: 1.000 - ETA: 9:04 - loss: 0.0100 - accuracy: 1.00 - ETA: 8:24 - loss: 0.0369 - accuracy: 0.98 - ETA: 7:52 - loss: 0.0319 - accuracy: 0.99 - ETA: 7:28 - loss: 0.0291 - accuracy: 0.99 - ETA: 7:05 - loss: 0.0344 - accuracy: 0.98 - ETA: 6:42 - loss: 0.0312 - accuracy: 0.99 - ETA: 6:19 - loss: 0.0285 - accuracy: 0.99 - ETA: 5:55 - loss: 0.0266 - accuracy: 0.99 - ETA: 5:29 - loss: 0.0261 - accuracy: 0.99 - ETA: 5:01 - loss: 0.0243 - accuracy: 0.99 - ETA: 4:33 - loss: 0.0236 - accuracy: 0.99 - ETA: 4:04 - loss: 0.0222 - accuracy: 0.99 - ETA: 3:36 - loss: 0.0266 - accuracy: 0.99 - ETA: 3:08 - loss: 0.0261 - accuracy: 0.99 - ETA: 2:41 - loss: 0.0248 - accuracy: 0.99 - ETA: 2:13 - loss: 0.0237 - accuracy: 0.99 - ETA: 1:46 - loss: 0.0227 - accuracy: 0.99 - ETA: 1:19 - loss: 0.0219 - accuracy: 0.99 - ETA: 52s - loss: 0.0211 - accuracy: 0.9932 - ETA: 26s - loss: 0.0202 - accuracy: 0.993 - 891s 36s/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 2.4177 - val_accuracy: 0.6944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1cb011aecc0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "step_size_train = train_generator.n // train_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=step_size_train,\n",
    "                    epochs=10,\n",
    "                    validation_data=test_generator,\n",
    "                    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and labels\n",
    "os.makedirs(project_path + 'Models/' + model_name + '/', exist_ok=True)\n",
    "save_model_classes(project_path + 'Models/',\n",
    "                   model_name, train_generator, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "294px",
    "left": "1070px",
    "right": "30px",
    "top": "120px",
    "width": "340px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
