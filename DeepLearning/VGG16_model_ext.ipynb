{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:11:14.216688Z",
     "start_time": "2020-01-17T14:11:12.542348Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import operator\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from shutil import copyfile\n",
    "import shutil\n",
    "\n",
    "import pickle\n",
    "\n",
    "# keras : librairie de deep learning\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, InputLayer, ReLU, AveragePooling2D, Softmax\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecure avec keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:11:14.274406Z",
     "start_time": "2020-01-17T14:11:14.266771Z"
    }
   },
   "outputs": [],
   "source": [
    "def sep_train_test(new_paths = ['Split_Data/Airliners/Train', 'Split_Data/Airliners/Test'], path = 'G7_scrapping/Airliners/data', airbus_planes = ['A320', 'A321', 'A350', 'A330'], boeing_planes = ['737', '747', '757', '777'], split_limite = .7):\n",
    "    os.makedirs(new_paths[0], exist_ok = True)\n",
    "    os.makedirs(new_paths[1], exist_ok = True)\n",
    "    \n",
    "    for fd in os.listdir(new_paths[0]):\n",
    "        shutil.rmtree(new_paths[0] + '/' + fd, ignore_errors=True)\n",
    "        \n",
    "    for fd in os.listdir(new_paths[1]):\n",
    "        shutil.rmtree(new_paths[1] + '/' + fd, ignore_errors=True)\n",
    "    \n",
    "    for plane in airbus_planes:\n",
    "        os.makedirs(new_paths[0] + '/' + plane)\n",
    "        os.makedirs(new_paths[1] + '/' + plane)\n",
    "        \n",
    "        for pict in os.listdir(path + '/Airbus/' + plane):\n",
    "            rand = np.random.random()\n",
    "            if rand <= split_limite:\n",
    "                copyfile(path + '/Airbus/' + plane + '/' + pict, new_paths[0] + '/' + plane + '/' + pict)\n",
    "            else:\n",
    "                copyfile(path + '/Airbus/' + plane + '/' + pict, new_paths[1] + '/' + plane + '/' + pict)\n",
    "                \n",
    "    for plane in boeing_planes:\n",
    "        os.makedirs(new_paths[0] + '/' + plane)\n",
    "        os.makedirs(new_paths[1] + '/' + plane)\n",
    "        \n",
    "        for pict in os.listdir(path + '/Boeing/' + plane):\n",
    "            rand = np.random.random()\n",
    "            if rand <= split_limite:\n",
    "                copyfile(path + '/Boeing/' + plane + '/' + pict, new_paths[0] + '/' + plane + '/' + pict)\n",
    "            else:\n",
    "                copyfile(path + '/Boeing/' + plane + '/' + pict, new_paths[1] + '/' + plane + '/' + pict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:11:20.541998Z",
     "start_time": "2020-01-17T14:11:14.505215Z"
    }
   },
   "outputs": [],
   "source": [
    "sep_train_test(airbus_planes = ['A320', 'A321', 'A350', 'A330', 'A380'], boeing_planes = ['737', '747', '757', '777'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:11:20.595710Z",
     "start_time": "2020-01-17T14:11:20.592641Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_format(path = 'Split_Data/Airliners/Test', old_format = 'jpg', new_format = 'png'):\n",
    "    for file in os.listdir(path):\n",
    "        print(file)\n",
    "        for pict in os.listdir(path + '/' + file):\n",
    "            if pict[-len(old_format):] == old_format:\n",
    "                im = Image.open(path + '/' + file + '/' + pict)\n",
    "                im.save(path + '/' + file + '/' + pict[:-len(old_format)] + new_format)\n",
    "                os.remove(path + '/' + file + '/' + pict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:11:50.660665Z",
     "start_time": "2020-01-17T14:11:20.642607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737\n",
      "A330\n",
      "747\n",
      "777\n",
      "757\n",
      "A350\n",
      "A320\n",
      "A380\n",
      "A321\n"
     ]
    }
   ],
   "source": [
    "convert_format(path = 'Split_Data/Airliners/Train', old_format = 'png', new_format = 'jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:11:50.721113Z",
     "start_time": "2020-01-17T14:11:50.712053Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_augmentation(train_path, coeff_creation = 2, rotation_range = 10, width_shift_range = .2, height_shift_range = .2, shear_range = .2, zoom_range = .2, horizontal_flip = True, nb_img = 10, save_format = 'jpg'):\n",
    "    classes = os.listdir(train_path)\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "           rotation_range=rotation_range,\n",
    "           width_shift_range=width_shift_range,\n",
    "           height_shift_range=height_shift_range,\n",
    "           shear_range=shear_range,\n",
    "           zoom_range=zoom_range,\n",
    "           horizontal_flip=horizontal_flip,\n",
    "           fill_mode='nearest')\n",
    "    \n",
    "    for classe in classes:\n",
    "        picts = os.listdir(train_path + '/' + classe)\n",
    "        print(classe)\n",
    "        \n",
    "        for pict in picts:\n",
    "            img = Image.open(train_path + '/' + classe + '/' + pict)\n",
    "            img = np.array(img)\n",
    "            img = img.reshape((1,) + img.shape)\n",
    "            i=1\n",
    "            \n",
    "            for batch in datagen.flow(img, batch_size=1, save_to_dir=train_path, save_prefix=classe + '/' + classe, save_format=save_format):\n",
    "                i += 1\n",
    "                if i > coeff_creation:\n",
    "                    break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:14:28.212770Z",
     "start_time": "2020-01-17T14:11:50.770013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737\n",
      "A330\n",
      "747\n",
      "777\n",
      "757\n",
      "A350\n",
      "A320\n",
      "A380\n",
      "A321\n"
     ]
    }
   ],
   "source": [
    "data_augmentation('Split_Data/Airliners/Train', coeff_creation = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:14:35.336920Z",
     "start_time": "2020-01-17T14:14:35.332424Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:14:37.818654Z",
     "start_time": "2020-01-17T14:14:36.796871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17987 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory('Split_Data/Airliners/Train',\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:14:40.308551Z",
     "start_time": "2020-01-17T14:14:40.301971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'737': 0,\n",
       " '747': 1,\n",
       " '757': 2,\n",
       " '777': 3,\n",
       " 'A320': 4,\n",
       " 'A321': 5,\n",
       " 'A330': 6,\n",
       " 'A350': 7,\n",
       " 'A380': 8}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:14:41.695499Z",
     "start_time": "2020-01-17T14:14:41.585600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = train_datagen.flow_from_directory('Split_Data/Airliners/Test copie',\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Modèle Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T10:31:11.673618Z",
     "start_time": "2020-01-09T10:31:11.664997Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape = (256,256,1), nb_couches = 5, nb_neuronnes = 10, kernel = (3, 3), pool = (2, 2), nb_classes = 1):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "    \n",
    "    for i in range(nb_couches):\n",
    "        model.add(Conv2D(2**(nb_neuronnes + i), kernel_size=kernel))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "                  \n",
    "        model.add(Conv2D(2**(nb_neuronnes + i), kernel_size=kernel))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        \n",
    "        model.add(MaxPooling2D(pool_size=pool))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    \n",
    "    model.add(Dense(nb_classes, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T10:31:13.003123Z",
     "start_time": "2020-01-09T10:31:12.249334Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_71 (Conv2D)           (None, 254, 254, 16)      448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 254, 254, 16)      64        \n",
      "_________________________________________________________________\n",
      "re_lu_82 (ReLU)              (None, 254, 254, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 252, 252, 16)      2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 252, 252, 16)      64        \n",
      "_________________________________________________________________\n",
      "re_lu_83 (ReLU)              (None, 252, 252, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 126, 126, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 124, 124, 32)      4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 124, 124, 32)      128       \n",
      "_________________________________________________________________\n",
      "re_lu_84 (ReLU)              (None, 124, 124, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 122, 122, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 122, 122, 32)      128       \n",
      "_________________________________________________________________\n",
      "re_lu_85 (ReLU)              (None, 122, 122, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 61, 61, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 59, 59, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 59, 59, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_86 (ReLU)              (None, 59, 59, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 57, 57, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 57, 57, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_87 (ReLU)              (None, 57, 57, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 26, 26, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 26, 26, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_88 (ReLU)              (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_89 (ReLU)              (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 10, 10, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 10, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_90 (ReLU)              (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_91 (ReLU)              (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "re_lu_92 (ReLU)              (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu_93 (ReLU)              (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 5,909,521\n",
      "Trainable params: 5,904,465\n",
      "Non-trainable params: 5,056\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(input_shape = (256,256,3), nb_neuronnes = 4)#, nb_classes = ytrain.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T10:56:17.632305Z",
     "start_time": "2020-01-09T10:31:22.060535Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2403 samples, validate on 794 samples\n",
      "Epoch 1/5\n",
      "2403/2403 [==============================] - 310s 129ms/step - loss: 0.7931 - accuracy: 0.5734 - val_loss: 0.6665 - val_accuracy: 0.5957\n",
      "Epoch 2/5\n",
      "2403/2403 [==============================] - 299s 124ms/step - loss: 0.6023 - accuracy: 0.6787 - val_loss: 0.6893 - val_accuracy: 0.5592\n",
      "Epoch 3/5\n",
      "2403/2403 [==============================] - 293s 122ms/step - loss: 0.5261 - accuracy: 0.7399 - val_loss: 0.7679 - val_accuracy: 0.6222\n",
      "Epoch 4/5\n",
      "2403/2403 [==============================] - 292s 122ms/step - loss: 0.6316 - accuracy: 0.6633 - val_loss: 10.0990 - val_accuracy: 0.5151\n",
      "Epoch 5/5\n",
      "2403/2403 [==============================] - 293s 122ms/step - loss: 0.5147 - accuracy: 0.7511 - val_loss: 1.2679 - val_accuracy: 0.5781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1770a06a0>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "# Lancement de l'entraînement\n",
    "history = model.fit(data_train, ytrain, batch_size=batch_size, epochs=epochs,  verbose=1, validation_data=(data_test, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:14:46.103232Z",
     "start_time": "2020-01-17T14:14:45.197578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 4617      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 9)                 36        \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 40,941,421\n",
      "Trainable params: 26,223,643\n",
      "Non-trainable params: 14,717,778\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "\n",
    "'''x = Conv2D(256, kernel_size=(3, 3))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(256, kernel_size=(3, 3))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)'''\n",
    "\n",
    "#x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Dense(512)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "# dernière couche que sert a prédire la bonne classe\n",
    "x = Dense(9)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "predictions = Softmax()(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:28:16.480194Z",
     "start_time": "2020-01-17T13:28:13.440805Z"
    }
   },
   "outputs": [],
   "source": [
    "#model = load_model('model_ext_16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T15:24:33.075413Z",
     "start_time": "2020-01-17T14:14:53.723336Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "562/562 [==============================] - 4170s 7s/step - loss: 1.3722 - accuracy: 0.5343 - val_loss: 2.4877 - val_accuracy: 0.1597\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "E0117 16:24:33.009383 140735758197632 ultratb.py:147] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-efdd0b95db4c>\", line 13, in <module>\n",
      "    callbacks=[reduce_lr])\n",
      "  File \"/Users/paul/.local/lib/python3.7/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/paul/.local/lib/python3.7/site-packages/keras/engine/training.py\", line 1732, in fit_generator\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"/Users/paul/.local/lib/python3.7/site-packages/keras/engine/training_generator.py\", line 220, in fit_generator\n",
      "    reset_metrics=False)\n",
      "  File \"/Users/paul/.local/lib/python3.7/site-packages/keras/engine/training.py\", line 1514, in train_on_batch\n",
      "    outputs = self.train_function(ins)\n",
      "  File \"/Users/paul/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3740, in __call__\n",
      "    outputs = self._graph_fn(*converted_inputs)\n",
      "  File \"/Users/paul/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1081, in __call__\n",
      "    return self._call_impl(args, kwargs)\n",
      "  File \"/Users/paul/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1121, in _call_impl\n",
      "    return self._call_flat(args, self.captured_inputs, cancellation_manager)\n",
      "  File \"/Users/paul/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1224, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager)\n",
      "  File \"/Users/paul/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 511, in call\n",
      "    ctx=ctx)\n",
      "  File \"/Users/paul/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 61, in quick_execute\n",
      "    num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Applications/anaconda3/lib/python3.7/inspect.py\", line 1495, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/inspect.py\", line 1453, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Applications/anaconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Applications/anaconda3/lib/python3.7/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Applications/anaconda3/lib/python3.7/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "step_size_train=train_generator.n//train_generator.batch_size\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                              patience=1, \n",
    "                              verbose=1, \n",
    "                              factor=0.5, \n",
    "                              min_lr=0.00001)\n",
    "\n",
    "model.fit_generator(generator=train_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   epochs=2,\n",
    "                   validation_data = test_generator,\n",
    "                   callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T09:18:02.837876Z",
     "start_time": "2020-01-17T09:18:02.833545Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model_classes(path_mod: str, mod_name: str, train_generator, model):\n",
    "    \n",
    "    shutil.rmtree(path_mod + mod_name, ignore_errors = True)\n",
    "    os.makedirs(path_mod + mod_name)\n",
    "    label_map = (train_generator.class_indices)\n",
    "    with open(path_mod + mod_name + '/' + 'model_' + mod_name + '.pkl', \"wb\") as f:\n",
    "        pickle.dump(label_map, f)\n",
    "    model.save(path_mod + mod_name + '/' + 'model_'+ mod_name + '.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T09:18:04.068870Z",
     "start_time": "2020-01-17T09:18:03.476218Z"
    }
   },
   "outputs": [],
   "source": [
    "save_model_classes('Models/', '17-01', train_generator, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "294px",
    "left": "1070px",
    "right": "30px",
    "top": "120px",
    "width": "340px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
