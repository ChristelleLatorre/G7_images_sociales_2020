{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Wed Jan 15 09:28:16 2020\\nGroup 7\\n@authors : L.D.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Wed Jan 15 09:28:16 2020\n",
    "Group 7\n",
    "@authors : L.D.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T15:19:11.728311Z",
     "start_time": "2020-01-09T15:19:06.196795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import operator\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "\n",
    "# keras : librairie de deep learning\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, InputLayer, ReLU, AveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# import for transfer learning\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run g7_functions_for_models.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecure avec keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seat_annot = pd.read_csv('C:/Users/Lilian/Documents/Projet_deep_learning/g7_SEATGURU_annotate.csv',sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Lilian/Documents/Projet_deep_learning/G7_SEATGURU/Int/Airbus/data_train\n",
      "C:/Users/Lilian/Documents/Projet_deep_learning/G7_SEATGURU/Int/Airbus/A320\n",
      "A320: 166 images\n",
      "C:/Users/Lilian/Documents/Projet_deep_learning/G7_SEATGURU/Int/Airbus/A321\n",
      "A321: 121 images\n",
      "C:/Users/Lilian/Documents/Projet_deep_learning/G7_SEATGURU/Int/Airbus/A330\n",
      "A330: 257 images\n",
      "C:/Users/Lilian/Documents/Projet_deep_learning/G7_SEATGURU/Int/Airbus/A350\n",
      "A350: 39 images\n",
      "C:/Users/Lilian/Documents/Projet_deep_learning/G7_SEATGURU/Int/Airbus/A380\n",
      "A380: 46 images\n"
     ]
    }
   ],
   "source": [
    "# path\n",
    "project_path = 'C:/Users/Lilian/Documents/Projet_deep_learning/'\n",
    "seatguru_path = 'Interpromo2020/All Data/ANALYSE IMAGE/IMG SEATGURU/'\n",
    "hackathon_path = 'C:/Users/Lilian/Documents/Projet_deep_learning/InputsHackathon_1/'\n",
    "crea_path = project_path + 'G7_SEATGURU/Int/Airbus/'\n",
    "new_paths = [crea_path + 'data_train', crea_path + 'data_test']\n",
    "print(crea_path + 'data_train')\n",
    "\n",
    "# Airbus type\n",
    "airbus_planes = ['A320', 'A321', 'A330', 'A350', 'A380']\n",
    "\n",
    "# SEATGURU\n",
    "# Create a directory for each class\n",
    "create_dirs_seatguru_type(df_seat_annot, project_path, seatguru_path, crea_path, aircraft_types=airbus_planes,\n",
    "                          view = 'Int', man = 'Airbus')\n",
    "\n",
    "# Split train and test\n",
    "split_train_test_seatguru_type(new_paths=new_paths, path=crea_path, aircraft_types=airbus_planes)\n",
    "\n",
    "# HACKATHON\n",
    "# Creation of train and test samples for Hackathon pictures\n",
    "split_train_test_hack(new_paths, hackathon_path, airbus_planes = ['A320', 'A330', 'A350', 'A380'], del_path = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_list(list_: list) -> list:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Transforms a list of lists into a flat list\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return [item for sublist in list_ for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgs(paths_list: list) -> list:\n",
    "    \"\"\"\n",
    "    From a list of images paths, get a list of PIL images\n",
    "    \"\"\"\n",
    "    imgs_list = [Image.open(project_path + data_path + '/'+ paths_list[i]) for i in range(len(paths_list))]\n",
    "\n",
    "    return imgs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = 'C:/Users/Lilian/Documents/Projet_deep_learning'\n",
    "data_path = '/G7_SEATGURU/Int'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Airbus']\n"
     ]
    }
   ],
   "source": [
    "# Get folders list (one item per aircraft manufacturer)\n",
    "\n",
    "folders_list = os.listdir(project_path + data_path)  # 2 folders: Airbus and Boeing\n",
    "print(folders_list)\n",
    "# Desired aircraft types\n",
    "Airbus_aircraft_types = ['A320', 'A321', 'A330', 'A350', 'A380']\n",
    "aircraft_types = list([Airbus_aircraft_types])\n",
    "# Lists: all images paths and names\n",
    "all_imgs_list = list()\n",
    "for k in range(len(folders_list)):\n",
    "    folder = folders_list[k]\n",
    "    aircraft_types_man = aircraft_types[k]\n",
    "    # For each folder (aircraft type), get list of all images names (with path)\n",
    "    for j in range(len(aircraft_types_man)):\n",
    "        img_list = os.listdir(project_path + data_path + '/' +folder+ '/'+ aircraft_types_man[j])\n",
    "        img_list = [folder +'/'+aircraft_types_man[j]  + '/' + img_list[k] for k in range(len(img_list))]\n",
    "        all_imgs_list.append(img_list)\n",
    "# Flat list\n",
    "\n",
    "all_imgs_flat_list = flat_list(all_imgs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_step_generator(classes: list, paths_list: list, imgs_per_class: int, shape: tuple,\n",
    "\n",
    "                       nb_win: int, greys: bool, nb_to_gen: int, img_gen: ImageDataGenerator) -> list:\n",
    "\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    From a list of reference images, performs a 2-step transformation to generate new images\n",
    "\n",
    "    of a chosen shape.\n",
    "\n",
    "    Step 1: Resizes images keeping height to width ratio, and generates a set of cropped images (sliding windows)\n",
    "\n",
    "    Step 2: Generates new images from Step 1 images, by applying rotations, zooms and shifts\n",
    "\n",
    "    \n",
    "\n",
    "    Parameters:\n",
    "\n",
    "        classes: list of desired classes, e.g.: ['Airbus', 'Boeing'], or a list of aircraft types\n",
    "\n",
    "        paths_list: list of images paths\n",
    "\n",
    "        imgs_per_class: desired number of images per class from Step 1 (resize + crop)\n",
    "\n",
    "        shape: desired shape (height, width)\n",
    "\n",
    "        nb_win: number of windows\n",
    "\n",
    "        greys: True for grey scale, False for colour scale\n",
    "\n",
    "        nb_to_gen: desired number of images per class from data generator\n",
    "\n",
    "        img_gen: ImageGenerator object\n",
    "\n",
    "  \n",
    "\n",
    "    Out:\n",
    "\n",
    "        datagen: list of generated arrays (representing images)\n",
    "\n",
    "  \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "    datawin = list()    \n",
    "\n",
    "    datagen = list()\n",
    "\n",
    "    \n",
    "\n",
    "    for class_ in classes:\n",
    "\n",
    "        print(class_)\n",
    "\n",
    "        \n",
    "\n",
    "        # Images paths list\n",
    "\n",
    "        class_imgs_path = [paths_list[k] for k in range(len(paths_list)) if class_ in paths_list[k]]\n",
    "\n",
    "\n",
    "\n",
    "        # Randomly choose images\n",
    "\n",
    "        class_imgs_subset = np.random.choice(class_imgs_path, size=imgs_per_class, replace=False)\n",
    "\n",
    "\n",
    "\n",
    "        # Get images\n",
    "\n",
    "        class_imgs = get_imgs(class_imgs_subset)\n",
    "\n",
    "\n",
    "\n",
    "        # Step 1: resize and crop on sliding windows\n",
    "\n",
    "        class_new_imgs = create_windows_imgs(class_imgs, shape=shape, nb_win=nb_win, greys=greys)\n",
    "\n",
    "        class_new_imgs = np.array(flat_list(class_new_imgs))\n",
    "\n",
    "        datawin.append(class_new_imgs)\n",
    "\n",
    "    \n",
    "\n",
    "        # Step 2: DataGenerator\n",
    "\n",
    "        class_datagen = datagen_class(class_new_imgs, nb_to_gen, img_gen)\n",
    "\n",
    "        class_datagen = class_datagen.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "        datagen.append(class_datagen)\n",
    "\n",
    "        \n",
    "\n",
    "    return datawin, datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows_imgs(init_imgs: list, shape: tuple, nb_win:int, greys: bool) -> list:\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        init_imgs: list of reference images\n",
    "        shape: desired shape (height, width)\n",
    "        nb_win: desired number of windows\n",
    "    Out:\n",
    "        new_imgs_all: list of all new arrays (representing images), created by cropping the reference images\n",
    "    \"\"\"\n",
    "    new_imgs_all = list()\n",
    "    for k in range(len(init_imgs)):\n",
    "        img = init_imgs[k]\n",
    "        new_imgs = create_windows_one_img(shape=shape, img=img, nb_win=nb_win, greys=greys)\n",
    "        new_imgs_all.append(new_imgs)\n",
    "    return new_imgs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows_one_img(shape: tuple, img: PIL.Image, nb_win: int, greys: bool) -> list:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        shape: desired shape (height, width)\n",
    "        img: reference image\n",
    "        nb_win: desired number of windows\n",
    "    Out:\n",
    "        arrs_crop: arrays (representing images) created by cropping the reference image\n",
    "    \"\"\"\n",
    "    img_arr = np.array(img)\n",
    "    if greys is True:\n",
    "        imgs_arr = np.mean(img_arr, axis = 2)\n",
    "    if img_arr.shape[0] <= img_arr.shape[1]:\n",
    "        # Choose fixed height, calculate width (to keep height to width ratio), resize\n",
    "        coef = img_arr.shape[0] / shape[0]\n",
    "        temp_width = int(img_arr.shape[1] / coef)\n",
    "        resized_img = img.resize((temp_width, shape[0]), Image.BILINEAR)\n",
    "    else:\n",
    "        # Choose fixed width, calculate height (to keep height to width ratio), resize\n",
    "        coef = img_arr.shape[1] / shape[1]\n",
    "        temp_height = int(img_arr.shape[0] / coef)\n",
    "        resized_img = img.resize((shape[1], temp_height), Image.BILINEAR)\n",
    "    # Convert resized image to array\n",
    "    if greys is True:\n",
    "        resized_arr = np.mean(np.array(resized_img), axis = 2)\n",
    "    else:\n",
    "        resized_arr = np.array(resized_img)\n",
    "    # Crop chosen number of windows\n",
    "    lag = int((int(resized_arr.shape[1]) - shape[1]) / nb_win -1)\n",
    "    bounds = np.arange(0, int(resized_arr.shape[1]) - shape[1], lag)\n",
    "    arrs_crop = list()\n",
    "    for k in bounds:\n",
    "        if greys:\n",
    "            cropped_img = resized_arr[:, k:k+shape[1]].reshape(shape[0], shape[1], 1)\n",
    "        else:\n",
    "            cropped_img = resized_arr[:, k:k+shape[1]]\n",
    "        arrs_crop.append(cropped_img)\n",
    "    return arrs_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(train_path, rotation_range = 10, width_shift_range = .2, height_shift_range = .2, shear_range = .2, zoom_range = .2, horizontal_flip = True, nb_img = 2):\n",
    "    classes = os.listdir(train_path)\n",
    "    datagen = ImageDataGenerator(\n",
    "           rotation_range=rotation_range,\n",
    "           width_shift_range=width_shift_range,\n",
    "           height_shift_range=height_shift_range,\n",
    "           shear_range=shear_range,\n",
    "           zoom_range=zoom_range,\n",
    "           horizontal_flip=horizontal_flip,\n",
    "           fill_mode='nearest')\n",
    "\n",
    "    for classe in classes:\n",
    "        picts = os.listdir(train_path + '/' + classe)\n",
    "        print(classe)        \n",
    "\n",
    "        for pict in picts:\n",
    "            img = Image.open(train_path + '/' + classe + '/' + pict)\n",
    "            img = np.array(img)\n",
    "            img = img.reshape((1,) + img.shape)\n",
    "            i=0\n",
    "            for batch in datagen.flow(img, batch_size=1, save_to_dir=train_path, save_prefix=classe + '/' + classe, save_format='jpg'):\n",
    "                i += 1\n",
    "                if i > nb_img:\n",
    "                    break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/Lilian/Documents/Projet_deep_learning/G7_SEATGURU/Int/Airbus/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A320\n",
      "A321\n",
      "A330\n",
      "A350\n",
      "A380\n"
     ]
    }
   ],
   "source": [
    "data_augmentation(path + 'data_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4805 images belonging to 5 classes.\n",
      "Found 537 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image data generator\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(path + 'data_train',\n",
    "                                                    target_size=(224,224),\n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=64,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(path + 'data_test',\n",
    "                                                   target_size=(224,224),\n",
    "                                                   color_mode='rgb',\n",
    "                                                   batch_size=64,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T09:22:00.420098Z",
     "start_time": "2020-01-10T09:21:59.487724Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 5, 5, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 17,283,397\n",
      "Trainable params: 2,564,613\n",
      "Non-trainable params: 14,718,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the base pre-trained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "# Add layers\n",
    "x = base_model.output\n",
    "\n",
    "x = Conv2D(256, kernel_size=(3, 3))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(256, kernel_size=(3, 3))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(1024)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Dense(512)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "# Last layer used to predict our classes\n",
    "predictions = Dense(5, activation = 'softmax')(x)\n",
    "\n",
    "# This is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Don't retrain pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=keras.optimizers.Adam(0.001),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce learning rate\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                              patience=2, \n",
    "                              verbose=1, \n",
    "                              factor=0.5, \n",
    "                              min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "step_size_train = 20 #train_generator.n // train_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=step_size_train,\n",
    "                    epochs=5,\n",
    "                    validation_data=test_generator,\n",
    "                    callbacks=[reduce_lr],\n",
    "                    validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "294px",
    "left": "1070px",
    "right": "30px",
    "top": "120px",
    "width": "340px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
