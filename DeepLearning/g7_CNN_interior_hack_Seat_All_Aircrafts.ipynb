{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Created on: Wed Jan 15 15:57:30 2020\n",
    "Group 7\n",
    "@author: C.T.D.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import operator\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "\n",
    "# keras : librairie de deep learning\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, InputLayer, ReLU, AveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# import for transfer learning\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading of csv file SEATGURU annontate\n",
    "csv_file = pd.read_csv('../g7_SEATGURU_annotate.csv', sep=';')\n",
    "Airbus_file = csv_file.loc[csv_file['aircraft_manufacturer']  == 'Airbus',:]\n",
    "Airbus_file = Airbus_file.loc[Airbus_file['view'] == 'Int']\n",
    "Boeing_file = csv_file.loc[csv_file['aircraft_manufacturer']  == 'Boeing',:]\n",
    "Boeing_file = Boeing_file.loc[Boeing_file['view'] == 'Int']\n",
    "# List name pictures\n",
    "list_img_Airbus = list(Airbus_file['name'])\n",
    "\n",
    "A320_file = Airbus_file.loc[Airbus_file['aircraft_type'] == 'A320']\n",
    "list_img_A320 = list(A320_file['name'])\n",
    "A321_file = Airbus_file.loc[Airbus_file['aircraft_type'] == 'A321']\n",
    "list_img_A321 = list(A321_file['name'])\n",
    "A330_file = Airbus_file.loc[Airbus_file['aircraft_type'] == 'A330']\n",
    "list_img_A330 = list(A330_file['name'])\n",
    "A350_file = Airbus_file.loc[Airbus_file['aircraft_type'] == 'A350']\n",
    "list_img_A350 = list(A350_file['name'])\n",
    "A380_file = Airbus_file.loc[Airbus_file['aircraft_type'] == 'A380']\n",
    "list_img_A380 = list(A380_file['name'])\n",
    "\n",
    "list_img_Boeing = list(Boeing_file['name'])\n",
    "\n",
    "B737_file = Boeing_file.loc[Boeing_file['aircraft_type'] == '737']\n",
    "list_img_B737 = list(B737_file['name'])\n",
    "B767_file = Boeing_file.loc[Boeing_file['aircraft_type'] == '767']\n",
    "list_img_B767 = list(B767_file['name'])\n",
    "B777_file = Boeing_file.loc[Boeing_file['aircraft_type'] == '777']\n",
    "list_img_B777 = list(B777_file['name'])\n",
    "B787_file = Boeing_file.loc[Boeing_file['aircraft_type'] == '787']\n",
    "list_img_B787 = list(B787_file['name'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_seatguru = './../All Data/ANALYSE IMAGE/IMG SEATGURU/'\n",
    "path_hackathon = './../Inputs Hackathon/'\n",
    "new_path_train = './../Split_data/Hack_Seatguru/Int/data_train'\n",
    "new_path_val = './../Split_data/Hack_Seatguru/Int/data_val'\n",
    "new_paths = [new_path_train, new_path_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split data in train and test samples for Seatguru pictures\n",
    "def split_train_test_Seatguru_cat(new_paths, path, \n",
    "                                  airbus_planes = [list_img_A320, list_img_A321, list_img_A330,list_img_A350, list_img_A380], \n",
    "                                  boeing_planes = [list_img_B737,list_img_B767,list_img_B777,list_img_B787],\n",
    "                                  split_limit = .7, s = 8):\n",
    "  \n",
    "    #Boeing\n",
    "\n",
    "    for plane in boeing_planes:\n",
    "        if plane == list_img_B737:\n",
    "            classe = '737'\n",
    "        if plane == list_img_B767:\n",
    "            classe = '767'\n",
    "        if plane == list_img_B777:\n",
    "            classe = '777'\n",
    "        if plane == list_img_B787:\n",
    "            classe = '787'\n",
    "        \n",
    "        shutil.rmtree(new_paths[0] + '/' + classe, ignore_errors = True)\n",
    "        os.makedirs(new_paths[0] + '/' + classe, exist_ok = True)\n",
    "        shutil.rmtree(new_paths[1] + '/' + classe, ignore_errors = True)\n",
    "        os.makedirs(new_paths[1]+ '/' + classe, exist_ok = True)\n",
    "        \n",
    "        random.seed(a = s)\n",
    "        random.shuffle(plane)\n",
    "\n",
    "        for pict in plane[:int(split_limit*len(plane))]:\n",
    "            copyfile(path + '/' + pict, new_paths[0] + '/' + classe + '/' +  pict)\n",
    "        for pict in plane[int(split_limit*len(plane)):]:\n",
    "            copyfile(path + '/' + pict, new_paths[1] + '/' + classe + '/' +  pict)\n",
    "            \n",
    "    #Airbus\n",
    "        \n",
    "    for plane in airbus_planes:\n",
    "\n",
    "        if plane == list_img_A320:\n",
    "            classe = 'A320'\n",
    "        if plane == list_img_A321:\n",
    "            classe = 'A321'\n",
    "        if plane == list_img_A330:\n",
    "            classe = 'A330'\n",
    "        if plane == list_img_A350:\n",
    "            classe = 'A350'\n",
    "        if plane == list_img_A380:\n",
    "            classe = 'A380'\n",
    "        \n",
    "        shutil.rmtree(new_paths[0] + '/' + classe, ignore_errors = True)\n",
    "        os.makedirs(new_paths[0] + '/' + classe, exist_ok = True)\n",
    "        shutil.rmtree(new_paths[1] + '/' + classe, ignore_errors = True)\n",
    "        os.makedirs(new_paths[1]+ '/' + classe, exist_ok = True)\n",
    "        \n",
    "        random.seed(a = s)\n",
    "        random.shuffle(plane)\n",
    "\n",
    "        for pict in plane[:int(split_limit*len(plane))]:\n",
    "            copyfile(path + '/' + pict, new_paths[0] + '/' + classe + '/' +  pict)\n",
    "        for pict in plane[int(split_limit*len(plane)):]:\n",
    "            copyfile(path + '/' + pict, new_paths[1] + '/' + classe + '/' +  pict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to split data in train and test samples for Hackathon pictures\n",
    "def  split_train_test_Hack_cat (new_paths:list, path:str, airbus_planes:list, split_limit:float=.7):\n",
    "    \n",
    "    #Airbus\n",
    "    \n",
    "    for plane in airbus_planes:\n",
    "        \n",
    "        os.makedirs(new_paths[0] + '/' + plane, exist_ok = True)\n",
    "        os.makedirs(new_paths[1] + '/' + plane, exist_ok = True)\n",
    "        \n",
    "        for pict in os.listdir(path + plane):\n",
    "            rand = np.random.random()\n",
    "            if rand <= split_limit:\n",
    "                copyfile(path + plane + '/' + pict, new_paths[0] + '/' + plane + '/' + pict)\n",
    "            else:\n",
    "                copyfile(path + plane + '/' + pict, new_paths[1] + '/' + plane + '/' + pict)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of train and test samples for Seatguru pictures\n",
    "split_train_test_Seatguru_cat(new_paths, path_seatguru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of train and test samples for Hackathon pictures\n",
    "split_train_test_Hack_cat(new_paths, path_hackathon, airbus_planes = ['A320', 'A330', 'A350', 'A380'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1766 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(new_path_train,\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'737': 0,\n",
       " '767': 1,\n",
       " '777': 2,\n",
       " '787': 3,\n",
       " 'A320': 4,\n",
       " 'A321': 5,\n",
       " 'A330': 6,\n",
       " 'A350': 7,\n",
       " 'A380': 8}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 747 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = train_datagen.flow_from_directory(new_path_val,\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape = (224, 224, 3), nb_couches = 4, kernel = (1,1), pool = (2, 2), nb_classes = 9):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "    \n",
    "    for i in range(1,5):\n",
    "        model.add(Conv2D(3**i, kernel_size=kernel))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "\n",
    "        model.add(Conv2D(3**i, kernel_size=kernel))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        \n",
    "        model.add(Conv2D(3**i, kernel_size=kernel))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "\n",
    "        model.add(Conv2D(3**i, kernel_size=kernel))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        \n",
    "        model.add(Conv2D(3**i, kernel_size=kernel))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=pool))\n",
    "    \n",
    "        \n",
    "    model.add(Conv2D(2, kernel_size=kernel))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(ReLU())        \n",
    "    \n",
    "    model.add(Conv2D(2, kernel_size=kernel))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(ReLU())        \n",
    "    \n",
    "    model.add(Conv2D(2, kernel_size=kernel))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(ReLU())        \n",
    "    \n",
    "    model.add(Conv2D(2, kernel_size=kernel))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(ReLU()) \n",
    "    \n",
    "    model.add(Conv2D(2, kernel_size=kernel))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(ReLU()) \n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=pool))    \n",
    "        \n",
    "    for i in range(4,2,-1):\n",
    "        model.add(Conv2D(3**i, kernel_size=kernel))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "\n",
    "        model.add(Conv2D(3**i, kernel_size=kernel))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        \n",
    "        model.add(Conv2D(3**i, kernel_size=kernel))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "\n",
    "        model.add(Conv2D(3**i, kernel_size=kernel))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "               \n",
    "        model.add(Conv2D(3**i, kernel_size=kernel))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=pool))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    \n",
    "    model.add(Dense(1024))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    \n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "re_lu_38 (ReLU)              (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "re_lu_39 (ReLU)              (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "re_lu_40 (ReLU)              (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "re_lu_41 (ReLU)              (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "re_lu_42 (ReLU)              (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 112, 112, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 112, 112, 9)       36        \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 112, 112, 9)       36        \n",
      "_________________________________________________________________\n",
      "re_lu_43 (ReLU)              (None, 112, 112, 9)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 112, 112, 9)       90        \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 112, 112, 9)       36        \n",
      "_________________________________________________________________\n",
      "re_lu_44 (ReLU)              (None, 112, 112, 9)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 112, 112, 9)       90        \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 112, 112, 9)       36        \n",
      "_________________________________________________________________\n",
      "re_lu_45 (ReLU)              (None, 112, 112, 9)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 112, 112, 9)       90        \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 112, 112, 9)       36        \n",
      "_________________________________________________________________\n",
      "re_lu_46 (ReLU)              (None, 112, 112, 9)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 112, 112, 9)       90        \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 112, 112, 9)       36        \n",
      "_________________________________________________________________\n",
      "re_lu_47 (ReLU)              (None, 112, 112, 9)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 56, 56, 9)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 56, 56, 27)        270       \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 56, 56, 27)        108       \n",
      "_________________________________________________________________\n",
      "re_lu_48 (ReLU)              (None, 56, 56, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 56, 56, 27)        756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 56, 56, 27)        108       \n",
      "_________________________________________________________________\n",
      "re_lu_49 (ReLU)              (None, 56, 56, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 56, 56, 27)        756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 56, 56, 27)        108       \n",
      "_________________________________________________________________\n",
      "re_lu_50 (ReLU)              (None, 56, 56, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 56, 56, 27)        756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 56, 56, 27)        108       \n",
      "_________________________________________________________________\n",
      "re_lu_51 (ReLU)              (None, 56, 56, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 56, 56, 27)        756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 56, 56, 27)        108       \n",
      "_________________________________________________________________\n",
      "re_lu_52 (ReLU)              (None, 56, 56, 27)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 28, 28, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 28, 28, 81)        2268      \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 28, 28, 81)        324       \n",
      "_________________________________________________________________\n",
      "re_lu_53 (ReLU)              (None, 28, 28, 81)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 28, 28, 81)        6642      \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 28, 28, 81)        324       \n",
      "_________________________________________________________________\n",
      "re_lu_54 (ReLU)              (None, 28, 28, 81)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 28, 28, 81)        6642      \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 28, 28, 81)        324       \n",
      "_________________________________________________________________\n",
      "re_lu_55 (ReLU)              (None, 28, 28, 81)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 28, 28, 81)        6642      \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 28, 28, 81)        324       \n",
      "_________________________________________________________________\n",
      "re_lu_56 (ReLU)              (None, 28, 28, 81)        0         \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_55 (Conv2D)           (None, 28, 28, 81)        6642      \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 28, 28, 81)        324       \n",
      "_________________________________________________________________\n",
      "re_lu_57 (ReLU)              (None, 28, 28, 81)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 14, 14, 81)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 14, 14, 2)         164       \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 14, 14, 2)         8         \n",
      "_________________________________________________________________\n",
      "re_lu_58 (ReLU)              (None, 14, 14, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 14, 14, 2)         6         \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 14, 14, 2)         8         \n",
      "_________________________________________________________________\n",
      "re_lu_59 (ReLU)              (None, 14, 14, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 14, 14, 2)         6         \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 14, 14, 2)         8         \n",
      "_________________________________________________________________\n",
      "re_lu_60 (ReLU)              (None, 14, 14, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 14, 14, 2)         6         \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 14, 14, 2)         8         \n",
      "_________________________________________________________________\n",
      "re_lu_61 (ReLU)              (None, 14, 14, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 14, 14, 2)         6         \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 14, 14, 2)         8         \n",
      "_________________________________________________________________\n",
      "re_lu_62 (ReLU)              (None, 14, 14, 2)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 7, 7, 2)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 7, 7, 81)          243       \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 7, 7, 81)          324       \n",
      "_________________________________________________________________\n",
      "re_lu_63 (ReLU)              (None, 7, 7, 81)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 7, 7, 81)          6642      \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 7, 7, 81)          324       \n",
      "_________________________________________________________________\n",
      "re_lu_64 (ReLU)              (None, 7, 7, 81)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 7, 7, 81)          6642      \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 7, 7, 81)          324       \n",
      "_________________________________________________________________\n",
      "re_lu_65 (ReLU)              (None, 7, 7, 81)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 7, 7, 81)          6642      \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 7, 7, 81)          324       \n",
      "_________________________________________________________________\n",
      "re_lu_66 (ReLU)              (None, 7, 7, 81)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 7, 7, 81)          6642      \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 7, 7, 81)          324       \n",
      "_________________________________________________________________\n",
      "re_lu_67 (ReLU)              (None, 7, 7, 81)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 3, 3, 81)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 3, 3, 27)          2214      \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 3, 3, 27)          108       \n",
      "_________________________________________________________________\n",
      "re_lu_68 (ReLU)              (None, 3, 3, 27)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 3, 3, 27)          756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 3, 3, 27)          108       \n",
      "_________________________________________________________________\n",
      "re_lu_69 (ReLU)              (None, 3, 3, 27)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 3, 3, 27)          756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 3, 3, 27)          108       \n",
      "_________________________________________________________________\n",
      "re_lu_70 (ReLU)              (None, 3, 3, 27)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 3, 3, 27)          756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 3, 3, 27)          108       \n",
      "_________________________________________________________________\n",
      "re_lu_71 (ReLU)              (None, 3, 3, 27)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 3, 3, 27)          756       \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 3, 3, 27)          108       \n",
      "_________________________________________________________________\n",
      "re_lu_72 (ReLU)              (None, 3, 3, 27)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 1, 27)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 27)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               14336     \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu_73 (ReLU)              (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "re_lu_74 (ReLU)              (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 9)                 9225      \n",
      "=================================================================\n",
      "Total params: 624,440\n",
      "Trainable params: 619,068\n",
      "Non-trainable params: 5,372\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sans reduction d'apprentissage si necessaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "55/55 [==============================] - ETA: 20:44 - loss: 0.4303 - accuracy: 0.878 - ETA: 12:00 - loss: 0.4033 - accuracy: 0.880 - ETA: 9:00 - loss: 0.4433 - accuracy: 0.875 - ETA: 7:24 - loss: 0.4497 - accuracy: 0.87 - ETA: 6:26 - loss: 0.4435 - accuracy: 0.87 - ETA: 5:43 - loss: 0.4474 - accuracy: 0.87 - ETA: 5:12 - loss: 0.4437 - accuracy: 0.86 - ETA: 4:46 - loss: 0.4390 - accuracy: 0.86 - ETA: 4:26 - loss: 0.4329 - accuracy: 0.87 - ETA: 4:09 - loss: 0.4296 - accuracy: 0.87 - ETA: 3:54 - loss: 0.4257 - accuracy: 0.87 - ETA: 3:41 - loss: 0.4254 - accuracy: 0.87 - ETA: 3:30 - loss: 0.4234 - accuracy: 0.87 - ETA: 3:20 - loss: 0.4241 - accuracy: 0.87 - ETA: 3:11 - loss: 0.4232 - accuracy: 0.87 - ETA: 3:03 - loss: 0.4212 - accuracy: 0.87 - ETA: 2:56 - loss: 0.4196 - accuracy: 0.87 - ETA: 2:49 - loss: 0.4190 - accuracy: 0.87 - ETA: 2:42 - loss: 0.4194 - accuracy: 0.87 - ETA: 2:36 - loss: 0.4175 - accuracy: 0.87 - ETA: 2:30 - loss: 0.4163 - accuracy: 0.87 - ETA: 2:24 - loss: 0.4149 - accuracy: 0.87 - ETA: 2:18 - loss: 0.4153 - accuracy: 0.87 - ETA: 2:13 - loss: 0.4187 - accuracy: 0.86 - ETA: 2:07 - loss: 0.4184 - accuracy: 0.87 - ETA: 2:02 - loss: 0.4190 - accuracy: 0.87 - ETA: 1:57 - loss: 0.4174 - accuracy: 0.87 - ETA: 1:53 - loss: 0.4169 - accuracy: 0.87 - ETA: 1:48 - loss: 0.4158 - accuracy: 0.87 - ETA: 1:44 - loss: 0.4142 - accuracy: 0.87 - ETA: 1:39 - loss: 0.4135 - accuracy: 0.87 - ETA: 1:35 - loss: 0.4137 - accuracy: 0.87 - ETA: 1:30 - loss: 0.4132 - accuracy: 0.87 - ETA: 1:26 - loss: 0.4127 - accuracy: 0.87 - ETA: 1:20 - loss: 0.4141 - accuracy: 0.87 - ETA: 1:15 - loss: 0.4139 - accuracy: 0.87 - ETA: 1:11 - loss: 0.4133 - accuracy: 0.87 - ETA: 1:07 - loss: 0.4127 - accuracy: 0.87 - ETA: 1:03 - loss: 0.4105 - accuracy: 0.87 - ETA: 59s - loss: 0.4102 - accuracy: 0.8724 - ETA: 55s - loss: 0.4090 - accuracy: 0.872 - ETA: 51s - loss: 0.4090 - accuracy: 0.872 - ETA: 47s - loss: 0.4076 - accuracy: 0.872 - ETA: 43s - loss: 0.4066 - accuracy: 0.872 - ETA: 39s - loss: 0.4070 - accuracy: 0.873 - ETA: 35s - loss: 0.4073 - accuracy: 0.873 - ETA: 31s - loss: 0.4066 - accuracy: 0.873 - ETA: 27s - loss: 0.4056 - accuracy: 0.873 - ETA: 23s - loss: 0.4049 - accuracy: 0.874 - ETA: 19s - loss: 0.4042 - accuracy: 0.874 - ETA: 15s - loss: 0.4037 - accuracy: 0.874 - ETA: 11s - loss: 0.4035 - accuracy: 0.874 - ETA: 7s - loss: 0.4039 - accuracy: 0.874 - ETA: 3s - loss: 0.4033 - accuracy: 0.87 - 249s 5s/step - loss: 0.4026 - accuracy: 0.8753 - val_loss: 0.3602 - val_accuracy: 0.8889\n",
      "Epoch 2/5\n",
      "55/55 [==============================] - ETA: 3:18 - loss: 0.3804 - accuracy: 0.87 - ETA: 3:25 - loss: 0.4146 - accuracy: 0.87 - ETA: 3:19 - loss: 0.3944 - accuracy: 0.87 - ETA: 3:19 - loss: 0.3793 - accuracy: 0.88 - ETA: 3:20 - loss: 0.3816 - accuracy: 0.87 - ETA: 3:16 - loss: 0.3845 - accuracy: 0.88 - ETA: 3:11 - loss: 0.3853 - accuracy: 0.87 - ETA: 3:08 - loss: 0.3814 - accuracy: 0.87 - ETA: 3:03 - loss: 0.3829 - accuracy: 0.88 - ETA: 3:00 - loss: 0.3853 - accuracy: 0.88 - ETA: 2:55 - loss: 0.3861 - accuracy: 0.87 - ETA: 2:51 - loss: 0.3838 - accuracy: 0.88 - ETA: 2:36 - loss: 0.3794 - accuracy: 0.88 - ETA: 2:31 - loss: 0.3796 - accuracy: 0.88 - ETA: 2:27 - loss: 0.3799 - accuracy: 0.88 - ETA: 2:23 - loss: 0.3773 - accuracy: 0.88 - ETA: 2:20 - loss: 0.3765 - accuracy: 0.88 - ETA: 2:16 - loss: 0.3768 - accuracy: 0.88 - ETA: 2:13 - loss: 0.3770 - accuracy: 0.88 - ETA: 2:09 - loss: 0.3749 - accuracy: 0.88 - ETA: 2:05 - loss: 0.3765 - accuracy: 0.88 - ETA: 2:01 - loss: 0.3770 - accuracy: 0.88 - ETA: 1:57 - loss: 0.3757 - accuracy: 0.88 - ETA: 1:54 - loss: 0.3749 - accuracy: 0.88 - ETA: 1:50 - loss: 0.3738 - accuracy: 0.88 - ETA: 1:46 - loss: 0.3733 - accuracy: 0.88 - ETA: 1:42 - loss: 0.3717 - accuracy: 0.88 - ETA: 1:38 - loss: 0.3714 - accuracy: 0.88 - ETA: 1:34 - loss: 0.3715 - accuracy: 0.88 - ETA: 1:31 - loss: 0.3712 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3709 - accuracy: 0.88 - ETA: 1:23 - loss: 0.3715 - accuracy: 0.88 - ETA: 1:20 - loss: 0.3701 - accuracy: 0.88 - ETA: 1:16 - loss: 0.3713 - accuracy: 0.88 - ETA: 1:13 - loss: 0.3713 - accuracy: 0.88 - ETA: 1:09 - loss: 0.3703 - accuracy: 0.88 - ETA: 1:05 - loss: 0.3689 - accuracy: 0.88 - ETA: 1:01 - loss: 0.3687 - accuracy: 0.88 - ETA: 58s - loss: 0.3679 - accuracy: 0.8830 - ETA: 54s - loss: 0.3676 - accuracy: 0.882 - ETA: 51s - loss: 0.3671 - accuracy: 0.882 - ETA: 47s - loss: 0.3669 - accuracy: 0.883 - ETA: 43s - loss: 0.3663 - accuracy: 0.883 - ETA: 40s - loss: 0.3659 - accuracy: 0.883 - ETA: 36s - loss: 0.3656 - accuracy: 0.883 - ETA: 32s - loss: 0.3658 - accuracy: 0.883 - ETA: 29s - loss: 0.3657 - accuracy: 0.883 - ETA: 25s - loss: 0.3658 - accuracy: 0.883 - ETA: 21s - loss: 0.3655 - accuracy: 0.883 - ETA: 18s - loss: 0.3654 - accuracy: 0.883 - ETA: 14s - loss: 0.3650 - accuracy: 0.883 - ETA: 10s - loss: 0.3651 - accuracy: 0.883 - ETA: 7s - loss: 0.3646 - accuracy: 0.883 - ETA: 3s - loss: 0.3644 - accuracy: 0.88 - 237s 4s/step - loss: 0.3642 - accuracy: 0.8840 - val_loss: 0.3271 - val_accuracy: 0.8889\n",
      "Epoch 3/5\n",
      "55/55 [==============================] - ETA: 3:02 - loss: 0.4295 - accuracy: 0.88 - ETA: 3:08 - loss: 0.3938 - accuracy: 0.88 - ETA: 3:17 - loss: 0.3827 - accuracy: 0.88 - ETA: 3:11 - loss: 0.3757 - accuracy: 0.88 - ETA: 3:05 - loss: 0.3736 - accuracy: 0.88 - ETA: 3:04 - loss: 0.3693 - accuracy: 0.88 - ETA: 3:02 - loss: 0.3729 - accuracy: 0.88 - ETA: 2:57 - loss: 0.3740 - accuracy: 0.88 - ETA: 2:55 - loss: 0.3749 - accuracy: 0.88 - ETA: 2:53 - loss: 0.3732 - accuracy: 0.88 - ETA: 2:49 - loss: 0.3770 - accuracy: 0.88 - ETA: 2:45 - loss: 0.3775 - accuracy: 0.88 - ETA: 2:40 - loss: 0.3786 - accuracy: 0.88 - ETA: 2:35 - loss: 0.3777 - accuracy: 0.88 - ETA: 2:30 - loss: 0.3756 - accuracy: 0.88 - ETA: 2:25 - loss: 0.3737 - accuracy: 0.88 - ETA: 2:22 - loss: 0.3715 - accuracy: 0.88 - ETA: 2:18 - loss: 0.3695 - accuracy: 0.88 - ETA: 2:15 - loss: 0.3679 - accuracy: 0.88 - ETA: 2:11 - loss: 0.3681 - accuracy: 0.88 - ETA: 2:07 - loss: 0.3660 - accuracy: 0.88 - ETA: 2:03 - loss: 0.3649 - accuracy: 0.88 - ETA: 1:59 - loss: 0.3636 - accuracy: 0.88 - ETA: 1:55 - loss: 0.3641 - accuracy: 0.88 - ETA: 1:51 - loss: 0.3637 - accuracy: 0.88 - ETA: 1:48 - loss: 0.3631 - accuracy: 0.88 - ETA: 1:44 - loss: 0.3625 - accuracy: 0.88 - ETA: 1:41 - loss: 0.3624 - accuracy: 0.88 - ETA: 1:37 - loss: 0.3612 - accuracy: 0.88 - ETA: 1:33 - loss: 0.3611 - accuracy: 0.88 - ETA: 1:29 - loss: 0.3609 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3595 - accuracy: 0.88 - ETA: 1:22 - loss: 0.3577 - accuracy: 0.88 - ETA: 1:18 - loss: 0.3574 - accuracy: 0.88 - ETA: 1:15 - loss: 0.3567 - accuracy: 0.88 - ETA: 1:11 - loss: 0.3559 - accuracy: 0.88 - ETA: 1:07 - loss: 0.3561 - accuracy: 0.88 - ETA: 1:03 - loss: 0.3551 - accuracy: 0.88 - ETA: 59s - loss: 0.3559 - accuracy: 0.8862 - ETA: 56s - loss: 0.3558 - accuracy: 0.886 - ETA: 52s - loss: 0.3562 - accuracy: 0.886 - ETA: 48s - loss: 0.3560 - accuracy: 0.886 - ETA: 45s - loss: 0.3559 - accuracy: 0.886 - ETA: 40s - loss: 0.3555 - accuracy: 0.886 - ETA: 36s - loss: 0.3555 - accuracy: 0.886 - ETA: 33s - loss: 0.3552 - accuracy: 0.885 - ETA: 29s - loss: 0.3552 - accuracy: 0.885 - ETA: 25s - loss: 0.3557 - accuracy: 0.885 - ETA: 21s - loss: 0.3565 - accuracy: 0.885 - ETA: 18s - loss: 0.3579 - accuracy: 0.885 - ETA: 14s - loss: 0.3578 - accuracy: 0.885 - ETA: 10s - loss: 0.3575 - accuracy: 0.885 - ETA: 7s - loss: 0.3573 - accuracy: 0.885 - ETA: 3s - loss: 0.3570 - accuracy: 0.88 - 237s 4s/step - loss: 0.3571 - accuracy: 0.8858 - val_loss: 0.3427 - val_accuracy: 0.8889\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - ETA: 2:53 - loss: 0.3647 - accuracy: 0.88 - ETA: 2:55 - loss: 0.3585 - accuracy: 0.88 - ETA: 3:00 - loss: 0.3591 - accuracy: 0.88 - ETA: 3:03 - loss: 0.3521 - accuracy: 0.88 - ETA: 3:04 - loss: 0.3509 - accuracy: 0.88 - ETA: 3:01 - loss: 0.3446 - accuracy: 0.88 - ETA: 2:59 - loss: 0.3458 - accuracy: 0.88 - ETA: 2:58 - loss: 0.3456 - accuracy: 0.88 - ETA: 2:56 - loss: 0.3460 - accuracy: 0.88 - ETA: 2:52 - loss: 0.3449 - accuracy: 0.88 - ETA: 2:49 - loss: 0.3472 - accuracy: 0.88 - ETA: 2:45 - loss: 0.3510 - accuracy: 0.88 - ETA: 2:40 - loss: 0.3506 - accuracy: 0.88 - ETA: 2:35 - loss: 0.3511 - accuracy: 0.88 - ETA: 2:32 - loss: 0.3494 - accuracy: 0.88 - ETA: 2:27 - loss: 0.3486 - accuracy: 0.88 - ETA: 2:23 - loss: 0.3486 - accuracy: 0.88 - ETA: 2:20 - loss: 0.3500 - accuracy: 0.88 - ETA: 2:16 - loss: 0.3512 - accuracy: 0.88 - ETA: 2:11 - loss: 0.3517 - accuracy: 0.88 - ETA: 2:07 - loss: 0.3511 - accuracy: 0.88 - ETA: 2:03 - loss: 0.3505 - accuracy: 0.88 - ETA: 2:00 - loss: 0.3504 - accuracy: 0.88 - ETA: 1:56 - loss: 0.3519 - accuracy: 0.88 - ETA: 1:52 - loss: 0.3514 - accuracy: 0.88 - ETA: 1:48 - loss: 0.3511 - accuracy: 0.88 - ETA: 1:44 - loss: 0.3515 - accuracy: 0.88 - ETA: 1:40 - loss: 0.3502 - accuracy: 0.88 - ETA: 1:37 - loss: 0.3509 - accuracy: 0.88 - ETA: 1:33 - loss: 0.3516 - accuracy: 0.88 - ETA: 1:29 - loss: 0.3521 - accuracy: 0.88 - ETA: 1:25 - loss: 0.3516 - accuracy: 0.88 - ETA: 1:21 - loss: 0.3537 - accuracy: 0.88 - ETA: 1:17 - loss: 0.3535 - accuracy: 0.88 - ETA: 1:14 - loss: 0.3535 - accuracy: 0.88 - ETA: 1:10 - loss: 0.3532 - accuracy: 0.88 - ETA: 1:06 - loss: 0.3528 - accuracy: 0.88 - ETA: 1:01 - loss: 0.3529 - accuracy: 0.88 - ETA: 58s - loss: 0.3521 - accuracy: 0.8851 - ETA: 54s - loss: 0.3528 - accuracy: 0.885 - ETA: 51s - loss: 0.3531 - accuracy: 0.885 - ETA: 47s - loss: 0.3530 - accuracy: 0.885 - ETA: 43s - loss: 0.3527 - accuracy: 0.885 - ETA: 40s - loss: 0.3520 - accuracy: 0.885 - ETA: 36s - loss: 0.3519 - accuracy: 0.885 - ETA: 32s - loss: 0.3516 - accuracy: 0.885 - ETA: 29s - loss: 0.3508 - accuracy: 0.885 - ETA: 25s - loss: 0.3506 - accuracy: 0.885 - ETA: 21s - loss: 0.3500 - accuracy: 0.885 - ETA: 18s - loss: 0.3498 - accuracy: 0.885 - ETA: 14s - loss: 0.3498 - accuracy: 0.885 - ETA: 10s - loss: 0.3495 - accuracy: 0.885 - ETA: 7s - loss: 0.3492 - accuracy: 0.885 - ETA: 3s - loss: 0.3491 - accuracy: 0.88 - 237s 4s/step - loss: 0.3488 - accuracy: 0.8856 - val_loss: 0.3138 - val_accuracy: 0.8889\n",
      "Epoch 5/5\n",
      "55/55 [==============================] - ETA: 2:53 - loss: 0.3635 - accuracy: 0.88 - ETA: 2:50 - loss: 0.3607 - accuracy: 0.88 - ETA: 2:52 - loss: 0.3657 - accuracy: 0.88 - ETA: 2:54 - loss: 0.3590 - accuracy: 0.88 - ETA: 3:00 - loss: 0.3531 - accuracy: 0.88 - ETA: 3:02 - loss: 0.3487 - accuracy: 0.88 - ETA: 2:59 - loss: 0.3514 - accuracy: 0.88 - ETA: 2:55 - loss: 0.3534 - accuracy: 0.88 - ETA: 2:53 - loss: 0.3514 - accuracy: 0.88 - ETA: 2:50 - loss: 0.3517 - accuracy: 0.88 - ETA: 2:48 - loss: 0.3505 - accuracy: 0.88 - ETA: 2:46 - loss: 0.3493 - accuracy: 0.88 - ETA: 2:41 - loss: 0.3480 - accuracy: 0.88 - ETA: 2:36 - loss: 0.3459 - accuracy: 0.88 - ETA: 2:31 - loss: 0.3457 - accuracy: 0.88 - ETA: 2:28 - loss: 0.3476 - accuracy: 0.88 - ETA: 2:23 - loss: 0.3472 - accuracy: 0.88 - ETA: 2:19 - loss: 0.3485 - accuracy: 0.88 - ETA: 2:16 - loss: 0.3486 - accuracy: 0.88 - ETA: 2:12 - loss: 0.3487 - accuracy: 0.88 - ETA: 2:03 - loss: 0.3446 - accuracy: 0.88 - ETA: 2:00 - loss: 0.3447 - accuracy: 0.88 - ETA: 1:56 - loss: 0.3449 - accuracy: 0.88 - ETA: 1:52 - loss: 0.3444 - accuracy: 0.88 - ETA: 1:49 - loss: 0.3433 - accuracy: 0.88 - ETA: 1:46 - loss: 0.3430 - accuracy: 0.88 - ETA: 1:42 - loss: 0.3435 - accuracy: 0.88 - ETA: 1:39 - loss: 0.3441 - accuracy: 0.88 - ETA: 1:35 - loss: 0.3450 - accuracy: 0.88 - ETA: 1:31 - loss: 0.3451 - accuracy: 0.88 - ETA: 1:27 - loss: 0.3443 - accuracy: 0.88 - ETA: 1:24 - loss: 0.3444 - accuracy: 0.88 - ETA: 1:20 - loss: 0.3452 - accuracy: 0.88 - ETA: 1:16 - loss: 0.3447 - accuracy: 0.88 - ETA: 1:12 - loss: 0.3446 - accuracy: 0.88 - ETA: 1:09 - loss: 0.3445 - accuracy: 0.88 - ETA: 1:05 - loss: 0.3448 - accuracy: 0.88 - ETA: 1:02 - loss: 0.3444 - accuracy: 0.88 - ETA: 58s - loss: 0.3442 - accuracy: 0.8871 - ETA: 54s - loss: 0.3445 - accuracy: 0.887 - ETA: 51s - loss: 0.3441 - accuracy: 0.887 - ETA: 47s - loss: 0.3440 - accuracy: 0.887 - ETA: 43s - loss: 0.3441 - accuracy: 0.887 - ETA: 40s - loss: 0.3441 - accuracy: 0.887 - ETA: 36s - loss: 0.3435 - accuracy: 0.887 - ETA: 32s - loss: 0.3434 - accuracy: 0.887 - ETA: 29s - loss: 0.3434 - accuracy: 0.887 - ETA: 25s - loss: 0.3434 - accuracy: 0.887 - ETA: 21s - loss: 0.3434 - accuracy: 0.887 - ETA: 18s - loss: 0.3431 - accuracy: 0.887 - ETA: 14s - loss: 0.3425 - accuracy: 0.887 - ETA: 10s - loss: 0.3427 - accuracy: 0.887 - ETA: 7s - loss: 0.3430 - accuracy: 0.887 - ETA: 3s - loss: 0.3428 - accuracy: 0.88 - 236s 4s/step - loss: 0.3431 - accuracy: 0.8875 - val_loss: 0.3415 - val_accuracy: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x198a3e3e080>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size_train=train_generator.n//train_generator.batch_size\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                              patience=1, \n",
    "                              verbose=1, \n",
    "                              factor=0.5, \n",
    "                              min_lr=0.00001)\n",
    "\n",
    "model.fit_generator(generator=train_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   epochs=5,\n",
    "                   validation_data = test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
