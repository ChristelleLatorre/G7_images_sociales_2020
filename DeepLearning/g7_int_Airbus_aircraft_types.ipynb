{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "created on: Fri Jan 15 11:21:27 2020\n",
    "<br>\n",
    "Group 7\n",
    "<br>\n",
    "@author: E.G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T15:19:11.728311Z",
     "start_time": "2020-01-09T15:19:06.196795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\emma.grandgirard\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\emma.grandgirard\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\emma.grandgirard\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\emma.grandgirard\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\emma.grandgirard\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\emma.grandgirard\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "from shutil import copyfile\n",
    "\n",
    "# deep learning\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, InputLayer, ReLU, AveragePooling2D\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = 'C:/Users/emma.grandgirard/Documents/B - Projet Interpromo/'\n",
    "data_path = 'Data/data_Interpromo2020/Interpromo2020/All Data/ANALYSE IMAGE/IMG SEATGURU/'\n",
    "\n",
    "# Images parameters\n",
    "size = (224, 224)\n",
    "greys = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read annotated CSV\n",
    "ind_int = pd.read_csv(project_path + 'CSV_annotate/SEATGURU/g7_SEATGURU_Int.csv', sep=';',\n",
    "                      engine='python', index_col=None, encoding='utf-8')\n",
    "\n",
    "ind_int = ind_int['Picture name'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1043\n"
     ]
    }
   ],
   "source": [
    "imgs_list = os.listdir(project_path + data_path)\n",
    "imgs_list = [img for img in imgs_list if 'Airbus' in img]\n",
    "print(len(imgs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs_seatguru(aircraft_types: list, new_path: str):\n",
    "    \n",
    "    \"\"\"Creates one directory per aircraft type with all corresponding images\"\"\"\n",
    "\n",
    "    for typ in aircraft_types:\n",
    "        typ_imgs = [[project_path + data_path + img, img] for img in imgs_list if (typ in img and img in ind_int)]\n",
    "        os.makedirs(new_path + typ, exist_ok=True)\n",
    "\n",
    "        for img in typ_imgs:\n",
    "            copyfile(img[0], new_path + typ + '/' + img[1])\n",
    "        \n",
    "        print(f'{typ}: {len(os.listdir(new_path + typ))} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A320: 161 images\n",
      "A321: 117 images\n",
      "A330: 250 images\n",
      "A350: 39 images\n"
     ]
    }
   ],
   "source": [
    "airbus_planes = ['A320', 'A321', 'A330', 'A350']\n",
    "crea_path = project_path + 'Data/Int/Airbus/'\n",
    "create_dirs_seatguru(aircraft_types=airbus_planes, new_path=crea_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split and read data with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_seatguru(new_paths: list, path: str, aircraft_types: list, split_limit: float=.7, s: int=8, \n",
    "                              ext: str='.jpg'):\n",
    "    \n",
    "    for typ in aircraft_types:\n",
    "        os.makedirs(new_paths[0] + '/' + typ, exist_ok=True)\n",
    "        os.makedirs(new_paths[1] + '/' + typ, exist_ok=True)\n",
    "        \n",
    "        picts = os.listdir(path + '/' + typ)\n",
    "        picts = [pic for pic in picts if pic[-4:] == ext]\n",
    "        random.seed(a=s)\n",
    "        random.shuffle(picts)\n",
    "        \n",
    "        for pict in picts[:int(split_limit * len(picts))]:\n",
    "            copyfile(path + typ + '/' + pict, new_paths[0] + '/' + typ + '/' + pict)\n",
    "            \n",
    "        for pict in picts[int(split_limit * len(picts)):]:\n",
    "            copyfile(path + typ + '/' + pict, new_paths[1] + '/' + typ + '/' + pict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_paths = [crea_path + 'data_train', crea_path + 'data_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test\n",
    "split_train_test_seatguru(new_paths=new_paths, path=crea_path,\n",
    "                          aircraft_types=airbus_planes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T15:26:28.959798Z",
     "start_time": "2020-01-09T15:26:19.480789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 395 images belonging to 4 classes.\n",
      "Found 172 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image data generator\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = train_datagen.flow_from_directory(new_paths[0],\n",
    "                                                    target_size=size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "\n",
    "test_generator = train_datagen.flow_from_directory(new_paths[1],\n",
    "                                                   target_size=size,\n",
    "                                                   color_mode='rgb',\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T09:22:00.420098Z",
     "start_time": "2020-01-10T09:21:59.487724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\emma.grandgirard\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 5, 5, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 17,282,884\n",
      "Trainable params: 2,564,100\n",
      "Non-trainable params: 14,718,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the base pre-trained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(size[0], size[1], 1 if greys else 3))\n",
    "\n",
    "# Add layers\n",
    "x = base_model.output\n",
    "\n",
    "x = Conv2D(256, kernel_size=(3, 3))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(256, kernel_size=(3, 3))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(1024)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Dense(512)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "# Last layer used to predict our classes\n",
    "predictions = Dense(4, activation = 'softmax')(x)\n",
    "\n",
    "# This is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Don't retrain pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce learning rate\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                              patience=2, \n",
    "                              verbose=1, \n",
    "                              factor=0.5, \n",
    "                              min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T09:46:07.626778Z",
     "start_time": "2020-01-10T09:27:13.063490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 404s 34s/step - loss: 1.4981 - accuracy: 0.4959 - val_loss: 5.4293 - val_accuracy: 0.4360\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 420s 35s/step - loss: 0.4988 - accuracy: 0.8567 - val_loss: 2.3475 - val_accuracy: 0.3430\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 437s 36s/step - loss: 0.1938 - accuracy: 0.9366 - val_loss: 1.4175 - val_accuracy: 0.4593\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 455s 38s/step - loss: 0.0451 - accuracy: 0.9896 - val_loss: 3.2514 - val_accuracy: 0.4884\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 266s 22s/step - loss: 0.0310 - accuracy: 0.9917 - val_loss: 2.3278 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 228s 19s/step - loss: 0.1236 - accuracy: 0.9766 - val_loss: 2.5691 - val_accuracy: 0.5116\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 246s 21s/step - loss: 0.1036 - accuracy: 0.9714 - val_loss: 1.8614 - val_accuracy: 0.4128\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 236s 20s/step - loss: 0.0805 - accuracy: 0.9835 - val_loss: 2.4599 - val_accuracy: 0.3895\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 227s 19s/step - loss: 0.0481 - accuracy: 0.9883 - val_loss: 2.5230 - val_accuracy: 0.4302\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 246s 20s/step - loss: 0.0211 - accuracy: 0.9896 - val_loss: 1.7611 - val_accuracy: 0.4826\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2d0bac9cb70>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size_train = train_generator.n // train_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=step_size_train,\n",
    "                    epochs=10,\n",
    "                    validation_data=test_generator,\n",
    "                    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run g7_pickle_save_load.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_classes(project_path + 'Models/', 'model_int_Airbus', train_generator, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "294px",
    "left": "1070px",
    "right": "30px",
    "top": "120px",
    "width": "340px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
