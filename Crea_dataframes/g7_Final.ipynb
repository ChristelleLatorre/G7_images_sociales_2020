{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Environment\" data-toc-modified-id=\"Environment-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Environment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Librairies\" data-toc-modified-id=\"Librairies-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Librairies</a></span></li><li><span><a href=\"#Data-Loading\" data-toc-modified-id=\"Data-Loading-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Data Loading</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Functions</a></span></li><li><span><a href=\"#Paths\" data-toc-modified-id=\"Paths-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Paths</a></span></li></ul></li><li><span><a href=\"#Preprocessing-functions\" data-toc-modified-id=\"Preprocessing-functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Preprocessing functions</a></span></li><li><span><a href=\"#Scraping\" data-toc-modified-id=\"Scraping-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Scraping</a></span><ul class=\"toc-item\"><li><span><a href=\"#Airliners\" data-toc-modified-id=\"Airliners-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Airliners</a></span></li><li><span><a href=\"#Google-images\" data-toc-modified-id=\"Google-images-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Google images</a></span></li></ul></li><li><span><a href=\"#Statistics-on-data\" data-toc-modified-id=\"Statistics-on-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Statistics on data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Seatguru\" data-toc-modified-id=\"Seatguru-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Seatguru</a></span></li><li><span><a href=\"#Hackathon\" data-toc-modified-id=\"Hackathon-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Hackathon</a></span></li></ul></li><li><span><a href=\"#Models\" data-toc-modified-id=\"Models-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Models</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Groupe 7 : Images sociales<span class=\"tocSkip\"></span>\n",
    "    \n",
    " Résultats\n",
    " \n",
    " Authors : All members\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Expliquer les choix : extérieur : utiliser directement les modèles\n",
    "Création des catégories extérieur vu de l'intérieur et meal        \n",
    "Transfert learning :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.0.0\n",
    "!pip install keras==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "2.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "# Scraping\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import urllib\n",
    "import urllib.request\n",
    "import requests\n",
    "import errno\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "project_path = './../'\n",
    "hack_path = project_path + 'InputsHackathon/'\n",
    "seatguru_path = project_path + 'Interpromo2020/All Data/ANALYSE IMAGE/IMG SEATGURU/'\n",
    "insta_path = project_path + 'Interpromo2020/All Data/ANALYSE IMAGE/IMG INSTAGRAM/'\n",
    "scrap_path = project_path + 'Scraping/'\n",
    "airliners_path = scrap_path + 'Airliners/data/'\n",
    "google_path = scrap_path + 'Google_img/'\n",
    "stats_path = project_path + 'ImagesStats/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'g7_functions_for_models.ipynb.py'` not found.\n",
      "ERROR:root:File `'preprocessing_functions.ipynb.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "%run g7_functions_for_models.ipynb\n",
    "%run preprocessing_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airliners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scraping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_photos_name_page(link):\n",
    "    req = requests.get(link)\n",
    "    soup = BeautifulSoup(req.text, \"lxml\")\n",
    "    AirCrafts = soup.find_all(\"div\", {\"class\":\"ps-v2-results-row\"})\n",
    "    list_DF = []\n",
    "    for air in AirCrafts:\n",
    "        try :\n",
    "            photo = air.find_all(\"img\")[0].attrs['src']\n",
    "            details_cell = air.find_all(\"div\", {\"class\" : \"ps-v2-results-col ps-v2-results-col-aircraft\"})[0]\n",
    "            details_cell = details_cell.find_all(\"div\", {'class' : \"ps-v2-results-col-content\"})[0]\n",
    "            details_cell = details_cell.find_all(\"div\", {\"class\":\"ps-v2-results-col-content-primary\"})[0]\n",
    "            name_cell = details_cell.find_all(\"div\", {\"class\":\"ps-v2-results-display-detail-no-wrapping\"})[1]\n",
    "            name = name_cell.a.text.strip().replace('/', '-')\n",
    "            if name.split()[0] in ['Airbus', 'Boeing']:\n",
    "                list_DF.append([photo, name.split()[0], name.split()[1].split('-')[0], name])\n",
    "        except :\n",
    "            pass\n",
    "    DF = pd.DataFrame(list_DF, columns = ['Photo', 'Company', 'Aircraft_type', 'Designation'])\n",
    "    return(DF)\n",
    "\n",
    "def create_directory (path):\n",
    "    os.makedirs(path + 'Airbus', exist_ok = True)   \n",
    "    os.makedirs(path + 'Boeing', exist_ok = True)\n",
    "\n",
    "\n",
    "def create_df_manufacturer(a,b,manuf_name):\n",
    "    l_df = []\n",
    "    dic_code_manuf = {'Airbus' : '2', 'Boeing' : '7'}\n",
    "    for i in range(a,b):\n",
    "        print(i)\n",
    "        link = 'https://www.airliners.net/search?aircraftManufacturer=' + dic_code_manuf[manuf_name]+ \\\n",
    "               '&photoCategory=23&sortBy=dateAccepted&sortOrder=desc&perPage=36&display=detail&page=' + str(i)\n",
    "        l_df.append(get_photos_name_page(link))\n",
    "    df = pd.concat(l_df, ignore_index = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_directory(airliners_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping for Airbus\n",
    "\n",
    "df_airbus_test = create_df_manufacturer(1,100,'Airbus')\n",
    "df_airbus_test.to_csv(airliners_path + 'Airbus/' + 'Airbus_test.csv', sep = ';')\n",
    "df_airbus_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbus_airliners = create_df_manufacturer(1,17452,'Airbus')\n",
    "df_airbus_airliners.to_csv(airliners_path + 'Airbus/Airbus_Airliners.csv', sep = ';')\n",
    "len(df_airbus_airliners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boeing_airliners = create_df_manufacturer(1,28482,'Boeing')\n",
    "df_boeing_airliners.to_csv(airliners_path + 'Boeing/Boeing_Airliners.csv', sep = ';')\n",
    "len(df_airbus_airliners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the images from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbus = pd.read_csv(airliners_path + 'Airbus/Airbus_Airliners.csv', sep = ';', index_col = 'Unnamed: 0')\n",
    "df_boeing = pd.read_csv(airliners_path + 'Boeing/Boeing_Airliners.csv', sep = ';', index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_type = {'Airbus' : ['A220', 'A300B4', 'A310', 'A318', 'A319', 'A320', 'A321', 'A330', 'A340', 'A350', 'A380'],\n",
    "            'Boeing' : ['717', '727', '737', '747', '757', '767', '777', '787']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation and storage of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_passengers(df, company, dic_type):\n",
    "    \"\"\"Create a new dataframe including only rows matching with commercial aircraft and adding a column\n",
    "    similar to the index.\n",
    "    \n",
    "    Parameters : \n",
    "        df (type dataframe): dataframe on which the selection must be proceed\n",
    "        company (type string): company name ('Airbus' or 'Boeing')\n",
    "        dic_type (type dictionary): keys are companies names and values are lists of the commercial aircraft \n",
    "        of the company \n",
    "    \n",
    "    Out :\n",
    "        df_passengers (type dataframe): modified dataframe  \n",
    "    \"\"\"\n",
    "        \n",
    "    df_passengers = df[df['Aircraft_type'].isin(dic_type[company])]\n",
    "    return df_passengers.assign(Number = df_passengers.index)\n",
    "\n",
    "\n",
    "\n",
    "def get_from_link_and_write(df, company, path):\n",
    "    \n",
    "    for el in df['Aircraft_type'].unique().tolist():\n",
    "        df_type = df[df['Aircraft_type']== el]\n",
    "        fold_name = path + company + '/' + el\n",
    "        os.makedirs(fold_name, exist_ok = True)\n",
    "        my_rows = zip(df_type['Number'], df_type['Photo'])\n",
    "        for (num, photo) in my_rows:\n",
    "            img_data = requests.get(photo).content\n",
    "            try :\n",
    "                i = Image.open(io.BytesIO(img_data))\n",
    "                i.save(fold_name + '/' + company + '_' + str(num) + '_' + el + '.png')\n",
    "            except :\n",
    "                print(el, num)\n",
    "                pass\n",
    "        \n",
    "def get_number_pic_per_type(df, nb, a):\n",
    "    # df : dataframe with only aircraft types of interest\n",
    "    # nb : number of pictures to create for ech aircraft type\n",
    "    ix = []\n",
    "    for el in df['Aircraft_type'].unique().tolist():\n",
    "        df_el = df[df['Aircraft_type']== el].copy()\n",
    "        df_el.reset_index(drop = True, inplace = True)\n",
    "        df_el = df_el.loc[a : a + min(nb-1, len(df_el))]\n",
    "        ix.extend(df_el['Number'].tolist())\n",
    "    df_nb = df[df['Number'].isin(ix)]\n",
    "    return df_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbus_passengers = create_df_passengers(df_airbus, 'Airbus', dic_type)\n",
    "df_boeing_passengers = create_df_passengers(df_boeing, 'Boeing', dic_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in dic_type['Airbus'] : \n",
    "    print(el, len(df_airbus[df_airbus['Aircraft_type']== el]))\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "for el in dic_type['Boeing'] : \n",
    "    print(el, len(df_boeing[df_boeing['Aircraft_type']== el]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbus_100 = get_number_pic_per_type(df_airbus_passengers, 100, 0)\n",
    "print(len(df_airbus_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbus_100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "get_from_link_and_write(df_airbus_100, 'Airbus', path)\n",
    "print(time.time()-start)\n",
    "# 125s needed to write 1100 pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbus_limited = get_number_pic_per_type(df_airbus_passengers, 1000, 0)\n",
    "get_from_link_and_write(df_airbus_limited, 'Airbus', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boeing_limited = get_number_pic_per_type(df_boeing_passengers, 1000, 0)\n",
    "get_from_link_and_write(df_boeing_limited, 'Boeing', path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "os.makedirs(google_path, exist_ok = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_df_types = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_img_by_aircraft_type(aircraft_type, dic_df_types):\n",
    "    \n",
    "    \"\"\" Update a dictionary with a dataframe giving links to the pictures found on the first page of Google Images\n",
    "    for a given request.\n",
    "    \n",
    "    Parameters :\n",
    "        aircraft_type (type string) : request for Google Images. Ex : 'Airbus A380'.\n",
    "        dic_df_types (type dict) : the keys are aircraft_type and the values are dataframes.\n",
    "    \"\"\" \n",
    "    \n",
    "    # Use of &tbs=sur:fc in the link to download only free_to_use images : \n",
    "    link = 'https://www.google.com/search?q=' + aircraft_type + \"&tbm=isch&tbs=sur:fc\"\n",
    "    df_images = pd.DataFrame(columns=[\"link\", \"request\", \"source\", \"source_2\"])\n",
    "    driver.get(link)\n",
    "    time.sleep(5)\n",
    "\n",
    "    blocks_images = driver.find_elements_by_xpath(\"//div[contains(@class,'rg_bx rg_di rg_el ivg-i')]\")\n",
    "    for bi in blocks_images:\n",
    "\n",
    "        site = bi.find_elements_by_xpath(\".//span\")\n",
    "        if site : site = site[0].get_attribute(\"innerHTML\")\n",
    "\n",
    "        source_1 = bi.find_elements_by_xpath(\".//img\")\n",
    "        if source_1 : source_1 = source_1[0].get_attribute(\"data-src\")\n",
    "\n",
    "        source_2 = bi.find_elements_by_xpath(\"./a\")\n",
    "        if source_2 : source_2 = source_2[0].get_attribute(\"href\")\n",
    "\n",
    "        row = pd.Series([site, aircraft_type, source_1, source_2], index=df_images.columns)\n",
    "        df_images = df_images.append(row, ignore_index=True, sort=False)\n",
    "        \n",
    "    dic_df_types[aircraft_type] = df_images\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_from_source_and_write(request, dic_df_types, path):\n",
    "    \n",
    "    print(request)\n",
    "    df = dic_df_types[request]\n",
    "    print(len(df))\n",
    "    df = df[df['source'].notnull()]\n",
    "    df.reset_index(inplace = True)\n",
    "    df = df.assign(Number = df.index)\n",
    "    print(len(df))\n",
    "    request = request.split()    \n",
    "    fold_name = path + request[0] + '/' + request[1]\n",
    "    os.makedirs(fold_name, exist_ok = True)\n",
    "    my_rows = zip(df['Number'], df['source'])\n",
    "    for (num, source) in my_rows:\n",
    "        img_data = requests.get(source).content\n",
    "        try :\n",
    "            i = Image.open(io.BytesIO(img_data))\n",
    "            i.save(fold_name + '/' + request[0] + '_' + request[1] + '_' + str(num) + '.png')\n",
    "        except :\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dic_type.keys():\n",
    "    print(key)\n",
    "    for aircraft in dic_type[key]:\n",
    "        print(aircraft)\n",
    "        google_img_by_aircraft_type(key + ' ' + aircraft, dic_df_types)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_df_types['Boeing 737'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with an aircraft type \n",
    "\n",
    "key = 'Boeing'\n",
    "#['717', '727', '737', '747', '757', '767', '777', '787']\n",
    "aircraft = '787'\n",
    "get_from_source_and_write(key + ' ' + aircraft, dic_df_types, path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dic_type.keys():\n",
    "    for aircraft in dic_type[key]:\n",
    "        get_from_source_and_write(key + ' ' + aircraft, dic_df_types, path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saver(dic_df_types):\n",
    "    for key, val in dic_df_types.items():\n",
    "        val.to_csv(google_path + \"Google_{}.csv\".format(str(key)), sep = ';')\n",
    "\n",
    "    with open(google_path + \"keys.txt\", \"w\") as f: #saving keys to file\n",
    "        f.write(str(list(dic_df_types.keys())))\n",
    "\n",
    "def loader():\n",
    "    \"\"\"Reading data from keys\"\"\"\n",
    "    with open(google_path + \"keys.txt\", \"r\") as f:\n",
    "        keys = eval(f.read())\n",
    "\n",
    "    dic = {}    \n",
    "    for key in keys:\n",
    "        dic[key] = pd.read_csv(google_path + \"Google_{}.csv\".format(str(key)), sep = ';')\n",
    "    return dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver(dic_df_types)\n",
    "dic = loader()\n",
    "dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics on data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seatguru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './../Interpromo2020/All Data/ANALYSE IMAGE/IMG SEATGURU/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f7917bf7640c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseatguru_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnb_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './../Interpromo2020/All Data/ANALYSE IMAGE/IMG SEATGURU/'"
     ]
    }
   ],
   "source": [
    "img_list = os.listdir(seatguru_path)\n",
    "nb_images = len(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all matrices (images)\n",
    "imgs = list()\n",
    "for i in range(nb_images):\n",
    "    img = imread(path + img_list[i])\n",
    "    imgs.append(img)\n",
    "\n",
    "# Init the dataframe that will contain all basic info about images\n",
    "imgs_df = pd.DataFrame(columns = ['name', 'format', 'height', 'width',\n",
    "                                  'height_to_width', 'ncol', 'aircraft_manufacturer', 'aircraft_type'])\n",
    "imgs_df.name = img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgs_formats(imgs: list, imgs_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Fills the DataFrame with pictures info (format and dimensions).\n",
    "    \n",
    "    Parameters:\n",
    "    imgs: list of arrays representing images\n",
    "    imgs_df: empty DataFrame with at least a 'name' column\n",
    "\n",
    "    Out:\n",
    "    imgs_df: DataFrame with 4 new columns: 'format', 'height', 'width',\n",
    "             'height_to_width', 'ncol', and one line per image\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Formats\n",
    "    imgs_df['format'] = imgs_df.name.apply(lambda x: x.split('.')[1])\n",
    "\n",
    "    # Shapes\n",
    "    heights = [imgs[k].shape[0] if len(imgs[k].shape) != 0 else 0 for k in range(len(imgs))]\n",
    "    widths = [imgs[k].shape[1] if len(imgs[k].shape) != 0 else 0 for k in range(len(imgs))]\n",
    "    ncols = [imgs[k].shape[2] if len(imgs[k].shape) != 0 else 0 for k in range(len(imgs))]\n",
    "\n",
    "    imgs_df['height'] = heights\n",
    "    imgs_df['width'] = widths\n",
    "    imgs_df['height_to_width'] = [x / y if y != 0 else 0 for x, y in zip(imgs_df.height, imgs_df.width)]\n",
    "    imgs_df['ncol'] = ncols\n",
    "\n",
    "    return imgs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to fill in DataFrame\n",
    "imgs_df = get_imgs_formats(imgs, imgs_df)\n",
    "\n",
    "# Aircraft manufacturers\n",
    "aircraft_manufacturers = ['Airbus' if 'Airbus' in imgs_df.name[k] \n",
    "                          else 'Boeing' if 'Boeing' in imgs_df.name[k]\n",
    "                          else 'Other' for k in range(len(imgs_df))]\n",
    "\n",
    "# Aircraft types\n",
    "aircraft_types = [name.split('_')[name.split('_').index(aircraft_manufacturer) + 1].split('-')[0]\n",
    "                  if aircraft_manufacturer in name.split('_') else ''\n",
    "                  for name, aircraft_manufacturer in zip(imgs_df.name, aircraft_manufacturers)]\n",
    "\n",
    "# Add missing As for Airbus aircrafts\n",
    "aircraft_types = [aircraft_types[k] \n",
    "                  if ('A' in aircraft_types[k] or '7' in aircraft_types[k] or aircraft_types[k] == '')\n",
    "                  else 'A' + aircraft_types[k] for k in range(len(aircraft_types))]\n",
    "\n",
    "# Remove Airbus 'neos' because we don't need that much detail\n",
    "aircraft_types = [aircraft_types[k].replace('neo', '') for k in range(len(aircraft_types))]\n",
    "\n",
    "# Remove Ds\n",
    "aircraft_types = [aircraft_types[k].replace('D', '') for k in range(len(aircraft_types))]\n",
    "\n",
    "# Fill in dataframe columns\n",
    "imgs_df.aircraft_manufacturer = aircraft_manufacturers\n",
    "imgs_df.aircraft_type = aircraft_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as csv\n",
    "path_tr =  './../CSV_annotate/SEATGURU/'\n",
    "os.makedirs(path_tr, exist_ok=True)\n",
    "imgs_df.to_csv(path_or_buf=path_tr + 'g7_SEATGURU.csv', sep=';', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Descriptive statistics¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(np.unique(imgs_df.format))} unique image format(s).')\n",
    "print(f'{len(np.unique(imgs_df.ncol))} unique ncol(s).')\n",
    "print(f'{len(np.unique(imgs_df.height_to_width))} unique height_to_width(s).')\n",
    "print(f'{len(np.unique(imgs_df.aircraft_type))} unique aircraft type(s).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(np.arange(nb_images)[imgs_df.aircraft_manufacturer == \"Airbus\"])} Airbus labelled images.')\n",
    "print(f'{len(np.arange(nb_images)[imgs_df.aircraft_manufacturer == \"Boeing\"])} Boeing labelled images.')\n",
    "print(f'{len(np.arange(nb_images)[imgs_df.aircraft_manufacturer == \"Other\"])} others.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(imgs_df: pd.DataFrame, col: pd.Series, col_name: str):\n",
    "\n",
    "    print(f'Max {col_name}: {np.max(col)}')\n",
    "    print(f'Median {col_name}: {np.median(col)}')\n",
    "    print(f'Min {col_name}: {np.min(col)}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions\n",
    "get_stats(imgs_df=imgs_df, col=imgs_df.height_to_width,\n",
    "          col_name='height_to_width')\n",
    "\n",
    "get_stats(imgs_df=imgs_df, col=imgs_df.height,\n",
    "          col_name='height')\n",
    "\n",
    "get_stats(imgs_df=imgs_df, col=imgs_df.width,\n",
    "          col_name='width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images per aircraft type\n",
    "pd.DataFrame(\n",
    "    pd.pivot_table(imgs_df,\n",
    "    index=['aircraft_manufacturer', 'aircraft_type'],\n",
    "    aggfunc='count').format.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Labellisation added manually : add SEATGURU annotate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General path \n",
    "directory = './Interpromo2020/All Data/ANALYSE IMAGE/INSTAGRAM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_insta(i, num_dim, end_path):\n",
    "    \"\"\"\n",
    "       \n",
    "    Parameters:\n",
    "        i (type: int): index\n",
    "        num_dim (type: int): index of the shape of the picture\n",
    "        end_path (type: string): work directory\n",
    "        \n",
    "    Out:\n",
    "        shape of the picture\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    try : \n",
    "        img = imread(end_path + '/' + str(i) + '.jpg')\n",
    "        return int(img.shape[num_dim])\n",
    "    except :\n",
    "        print(i)\n",
    "        return 0\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_insta(end_path): \n",
    "    \"\"\"\n",
    "    Return CSV file which contains shapes of all the pictures from the folder\n",
    "    \n",
    "    Parameters:\n",
    "        end_path (type: string): work directory\n",
    "        \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: complete the path\n",
    "    directory_complete = directory + end_path\n",
    "    \n",
    "    # Step 2: recover the name of each picture\n",
    "    list_pic = os.listdir(directory_complete)\n",
    "    list_pic = [int(el.split('.')[0]) for el in list_pic if el.split('.')[1] == 'jpg']\n",
    "    list_pic = sorted(list_pic)\n",
    "    \n",
    "    # Step 3: creation of a dataframe\n",
    "    df = pd.DataFrame(index = list_pic , columns = ['height', 'width'])\n",
    "    \n",
    "    # Step 4: duplicate the index column\n",
    "    df = df.assign(Number = df.index)\n",
    "    \n",
    "    # Step 5: application of the dim function on columns height and width\n",
    "    df['height'] = df['Number'].apply(lambda x : dim_insta(x, 0,directory_complete))\n",
    "    df['width'] = df['Number'].apply(lambda x : dim_insta(x, 1,directory_complete))\n",
    "    \n",
    "    \n",
    "    df = df.drop(['Number'], axis = 1)\n",
    "    \n",
    "    # Step : creation of the csv\n",
    "    df.to_csv(directory_complete + '/dataframe_' + end_path + '.csv', sep = ';', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insta_airbus = data_insta('airbus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insta_int = data_insta('aircraftinterior')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_insta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b726020776f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_insta_aircraft_seat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_insta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aircraftseat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_insta' is not defined"
     ]
    }
   ],
   "source": [
    "df_insta_aircraft_seat = data_insta('aircraftseat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_insta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b726020776f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_insta_aircraft_seat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_insta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aircraftseat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_insta' is not defined"
     ]
    }
   ],
   "source": [
    "df_insta_aircraft_seat = data_insta('aircraftseat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons commencé par essayer de comprendre la problématique pour définir le nombre de modèles à entraîner.\n",
    "Pour l'intérieur et pour l'extérieur, nous pensions commencer par construire un modèle qui prédit le constructeur puis un modèle qui prédit le modèle d'avion.\n",
    "\n",
    "Vu que nous avons obtenu des résultats satisfaisants pour les extérieurs d'avion en commençant par détecter en simultanés les modèles d'avion d'Airbus et de Boeing, nous n'avons pas utilisé pour l'extérieur.\n",
    "\n",
    "\n",
    "Nous avons commencé par tester des CNN (Donner des scores)\n",
    "Face aux résultats décevants, nous avons décidé de tenter le transfert learning.\n",
    "Nous avons donc repris les CNN en ajoutant au départ un réseau pré-entrainé.\n",
    "\n",
    "Or, pour les trois réseaux qui doivent prédire les intérieurs nous nous sommes heurtés au même problème, : l'accuracy au niveau de l'entrainement s'approche de 1, alors que l'acurracy au niveau de la validation  plafonne très rapidement. (Préciser la valeur pour chacun des modèles ? ) Vu qu'il y a peu d'images, le réseau apprend par coeur et ne peut pas généraliser.\n",
    "\n",
    "La structure du modèle employée est la suivante : \n",
    "\n",
    "Pour les intérieurs, nous avons également essayé plusieurs combinaisons pour détecter les modèles et le constructeur : \n",
    "Pour ce qui concerne Airbus : utiliser, Seatguru, utiliser les données du Hackhaton ou bien utiliser les deux combinées pour obtenir un plus grand nombre d'images.\n",
    "\n",
    "En effet, les données du Hackathon étaient plus nombreuses que les données de SeatGuru pour chaque type de modèle.\n",
    "Toutefois, les images sont différentes de celles qu'on peut trouver dans les réseaux sociaux puisqu'il n'y a jamais de personnes présentes. \n",
    "\n",
    "Face aux résultats décevants, nous avons cherché à pratiquer la data augmentation.(Combien d'images supplémentaires générées ?\n",
    "Les résultats n'étaient pas plus concluants.\n",
    "\n",
    "Le manque de données fournies, combinées avec le fait qu'au niveau du Hackhaton les données fournies sont différentes des données de test, ne permettent pas d'entraîner convenablement le modèle.\n",
    "\n",
    "Un plus grand nombre de données pourraient être une solution pour améliorer les performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewpoint "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exterior : Aircraft_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interior : Manufacturer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interiors : Airbus aircrafts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interiors : Boeing aircrafts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airbus exteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
