{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:11:14.216688Z",
     "start_time": "2020-01-17T14:11:12.542348Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import operator\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from shutil import copyfile\n",
    "import shutil\n",
    "\n",
    "import pickle\n",
    "\n",
    "# keras : librairie de deep learning\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, InputLayer, ReLU, AveragePooling2D, Softmax\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = './../' \n",
    "Airliners_path = project_path + 'Scraping/Airliners/data'\n",
    "new_paths = [project_path + 'Split_Data/Airliners/Train', project_path + 'Split_Data/Airliners/Test']\n",
    "airbus_planes = ['A320', 'A321', 'A330', 'A350']\n",
    "boeing_planes =  ['737', '747', '757', '777']\n",
    "\n",
    "# nb_types : number of classes to predict\n",
    "nb_types = len(airbus_planes) + len(boeing_planes)\n",
    "\n",
    "model_name = 'Ext_F_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run g7_functions_for_models_V2.ipynb\n",
    "#%run g7_data_augmentation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecure avec keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_train_test_airliners(Airliners_path, new_paths, airbus_planes = airbus_planes, boeing_planes = boeing_planes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:11:50.721113Z",
     "start_time": "2020-01-17T14:11:50.712053Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_augmentation(train_path, coeff_creation = 2, rotation_range = 10, width_shift_range = .2, \n",
    "                      height_shift_range = .2, shear_range = .2, zoom_range = .2, horizontal_flip = True, \n",
    "                      nb_img = 10, save_format = 'jpg'):\n",
    "   \n",
    "    classes = os.listdir(train_path)\n",
    " \n",
    "    datagen = ImageDataGenerator(\n",
    "           rotation_range=rotation_range,\n",
    "           width_shift_range=width_shift_range,\n",
    "           height_shift_range=height_shift_range,\n",
    "           shear_range=shear_range,\n",
    "           zoom_range=zoom_range,\n",
    "           horizontal_flip=horizontal_flip,\n",
    "           fill_mode='nearest')\n",
    "    \n",
    "    for classe in classes:\n",
    "        picts = os.listdir(train_path + '/' + classe)\n",
    "        print(classe)\n",
    "        \n",
    "        for pict in picts:\n",
    "            img = Image.open(train_path + '/' + classe + '/' + pict)\n",
    "            img = np.array(img)\n",
    "            img = img.reshape((1,) + img.shape)\n",
    "            i=1\n",
    "            \n",
    "            for batch in datagen.flow(img, batch_size=1, save_to_dir=train_path, save_prefix=classe + '/' + classe, save_format=save_format):\n",
    "                i += 1\n",
    "                if i > coeff_creation:\n",
    "                    break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:14:28.212770Z",
     "start_time": "2020-01-17T14:11:50.770013Z"
    }
   },
   "outputs": [],
   "source": [
    "#data_augmentation(project_path + 'Split_Data/Airliners/Train', coeff_creation = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:14:35.336920Z",
     "start_time": "2020-01-17T14:14:35.332424Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:14:37.818654Z",
     "start_time": "2020-01-17T14:14:36.796871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5600 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(project_path + 'Split_Data/Airliners/Train',\n",
    "                                                    target_size=(224,224),\n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:14:40.308551Z",
     "start_time": "2020-01-17T14:14:40.301971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'737': 0,\n",
       " '747': 1,\n",
       " '757': 2,\n",
       " '777': 3,\n",
       " 'A320': 4,\n",
       " 'A321': 5,\n",
       " 'A330': 6,\n",
       " 'A350': 7}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:14:41.695499Z",
     "start_time": "2020-01-17T14:14:41.585600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2400 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = train_datagen.flow_from_directory(project_path + 'Split_Data/Airliners/Test',\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:14:46.103232Z",
     "start_time": "2020-01-17T14:14:45.197578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 4104      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 40,940,904\n",
      "Trainable params: 26,223,128\n",
      "Non-trainable params: 14,717,776\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "\n",
    "'''x = Conv2D(256, kernel_size=(3, 3))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(256, kernel_size=(3, 3))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)'''\n",
    "\n",
    "#x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Dense(512)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "# dernière couche que sert a prédire la bonne classe\n",
    "x = Dense(nb_types)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "predictions = Softmax()(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:28:16.480194Z",
     "start_time": "2020-01-17T13:28:13.440805Z"
    }
   },
   "outputs": [],
   "source": [
    "#model = load_model('model_ext_16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T15:24:33.075413Z",
     "start_time": "2020-01-17T14:14:53.723336Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "175/175 [==============================] - 1292s 7s/step - loss: 1.2279 - accuracy: 0.6064 - val_loss: 0.7389 - val_accuracy: 0.7275\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 1279s 7s/step - loss: 0.5156 - accuracy: 0.9309 - val_loss: 0.5370 - val_accuracy: 0.7908\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 2799s 16s/step - loss: 0.3189 - accuracy: 0.9768 - val_loss: 0.5975 - val_accuracy: 0.7987\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 2056s 12s/step - loss: 0.2402 - accuracy: 0.9862 - val_loss: 0.5833 - val_accuracy: 0.8208\n",
      "Epoch 5/10\n",
      "175/175 [==============================] - 1325s 8s/step - loss: 0.2142 - accuracy: 0.9861 - val_loss: 0.5137 - val_accuracy: 0.8171\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/10\n",
      "175/175 [==============================] - 2396s 14s/step - loss: 0.1605 - accuracy: 0.9925 - val_loss: 0.5471 - val_accuracy: 0.8404\n",
      "Epoch 7/10\n",
      "175/175 [==============================] - 2564s 15s/step - loss: 0.1460 - accuracy: 0.9920 - val_loss: 0.5688 - val_accuracy: 0.8529\n",
      "Epoch 8/10\n",
      "175/175 [==============================] - 3078s 18s/step - loss: 0.1153 - accuracy: 0.9973 - val_loss: 0.7000 - val_accuracy: 0.8571\n",
      "Epoch 9/10\n",
      "175/175 [==============================] - 3980s 23s/step - loss: 0.1083 - accuracy: 0.9948 - val_loss: 0.6044 - val_accuracy: 0.8296\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/10\n",
      "175/175 [==============================] - 2971s 17s/step - loss: 0.0954 - accuracy: 0.9971 - val_loss: 0.3194 - val_accuracy: 0.8479\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f55da9ee050>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "step_size_train=train_generator.n//train_generator.batch_size\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                              patience=1, \n",
    "                              verbose=1, \n",
    "                              factor=0.5, \n",
    "                              min_lr=0.00001)\n",
    "\n",
    "model.fit_generator(generator=train_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   epochs=10,\n",
    "                   validation_data = test_generator,\n",
    "                   callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and labels\n",
    "os.makedirs(project_path + 'Models/' + model_name + '/', exist_ok=True)\n",
    "save_model_classes(project_path + 'Models/',\n",
    "                   model_name, train_generator, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "294px",
    "left": "1070px",
    "right": "30px",
    "top": "120px",
    "width": "340px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
