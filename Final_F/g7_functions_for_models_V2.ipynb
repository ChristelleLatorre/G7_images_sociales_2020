{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on: Thu Wed 15 09:44:36 2020\n",
    "Group 7\n",
    "@authors: V.B., E.G.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of train test files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeatGuru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs_seatguru_type(df_seat_annot, project_path, data_path, crea_path, aircraft_types: list, view : str ,\n",
    "                              man : str):\n",
    "    \n",
    "    \"\"\"Creates one directory per aircraft type with all corresponding images.\n",
    "    \n",
    "    Parameters:\n",
    "        df_seat_annot: Seatguru annotated DataFrame, containing the 'view' label\n",
    "        project_path: path to the project directory\n",
    "        data_path: path to the data directory\n",
    "        aircraft_types: list of aircraft types, e.g. ['A320', 'A330']\n",
    "        view: 'Int' or 'Ext'\n",
    "        man: 'Airbus' or 'Boeing'\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get Seatguru 'view' labels, and get a list of all images of required view (Interior or Exterior)\n",
    "        \n",
    "    ind_int = df_seat_annot[df_seat_annot['view']== view]['name'].tolist()\n",
    "    imgs_list = os.listdir(data_path)\n",
    "    imgs_man = [img for img in imgs_list if man in img]\n",
    "    crea_path = project_path + 'G7_SEATGURU/' + view + '/' + man + '/'\n",
    "    shutil.rmtree(crea_path, ignore_errors = True)\n",
    "    os.makedirs(crea_path)  \n",
    "        \n",
    "    \n",
    "    # For each aircraft type, create and fill a directory\n",
    "    \n",
    "    for typ in aircraft_types:\n",
    "        typ_imgs = [[data_path + img, img] for img in imgs_list if (typ in img and img in ind_int)]\n",
    "        #shutil.rmtree(crea_path + typ, ignore_errors = True)\n",
    "        os.makedirs(crea_path + typ)\n",
    "        print(crea_path + typ)\n",
    "\n",
    "        for img in typ_imgs:\n",
    "            copyfile(img[0], crea_path + typ + '/' + img[1])\n",
    "        \n",
    "        print(f'{typ}: {len(os.listdir(crea_path + typ))} images')\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_seatguru_type(new_paths: list, path: str, aircraft_types: list, split_limit: float=.7, \n",
    "                                   s: int=8, ext: str='.jpg'):\n",
    "    \n",
    "    \"\"\"Splits Seatguru images into train and test sets, to be used for aircraft types prediction.\n",
    "    \n",
    "    Parameters:\n",
    "        new_paths: paths to train and test\n",
    "        path: where to get the reference dataset\n",
    "        aircraft_types: list of aircraft types, e.g. ['A320', 'A330'] \n",
    "        split_limit: % of images to use as train set\n",
    "        s: random seed\n",
    "        ext: images extension\n",
    "        \n",
    "    \"\"\"\n",
    "    # Train-test split each aircraft type set, create and fill train and test folders\n",
    "    for typ in aircraft_types:\n",
    "        shutil.rmtree(new_paths[0] + '/' + typ, ignore_errors = True)\n",
    "        os.makedirs(new_paths[0] + '/' + typ)\n",
    "        shutil.rmtree(new_paths[1] + '/' + typ, ignore_errors = True)\n",
    "        os.makedirs(new_paths[1] + '/' + typ)\n",
    "        \n",
    "        picts = os.listdir(path + typ)\n",
    "        picts = [pic for pic in picts if pic[-4:] == ext]\n",
    "        random.seed(a=s)\n",
    "        random.shuffle(picts)\n",
    "        \n",
    "        for pict in picts[:int(split_limit * len(picts))]:\n",
    "            copyfile(path + typ + '/' + pict, new_paths[0] + '/' + typ + '/' + pict)\n",
    "   \n",
    "        for pict in picts[int(split_limit * len(picts)):]:\n",
    "            copyfile(path + typ + '/' + pict, new_paths[1] + '/' + typ + '/' + pict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_seatguru_view(new_paths: list, seatguru_path : str, views: list, df_seat_annot,\n",
    "                                   split_limit: float=.7, s: int=8, ext: str='.jpg'):\n",
    "\n",
    "    # Get Airbus and Boeing images names for Interior view\n",
    "    for el in views :\n",
    "        shutil.rmtree(new_paths[0] + el, ignore_errors=True)\n",
    "        os.makedirs(new_paths[0] + el)\n",
    "        shutil.rmtree(new_paths[1] + el, ignore_errors=True)\n",
    "        os.makedirs(new_paths[1] + el)\n",
    "        \n",
    "        df = df_seat_annot[df_seat_annot['view'] == el]\n",
    "        picts = df['name'].tolist()\n",
    "        random.seed(a=s)\n",
    "        random.shuffle(picts)\n",
    "        \n",
    "        for pict in picts[:int(split_limit * len(picts))]:\n",
    "                \n",
    "            copyfile(seatguru_path + pict, new_paths[0] + el + '/' + pict)\n",
    "            \n",
    "        for pict in picts[int(split_limit * len(picts)):]:\n",
    "            copyfile(seatguru_path + pict, new_paths[1] + el + '/' + pict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_seatguru_man(new_paths, seatguru_path, list_airbus, list_boeing, split_limit = .7, s = 8):\n",
    "    \n",
    "    \"\"\"Splits Seatguru images into train and test sets, to be used for aircraft manufacturers prediction.\n",
    "\n",
    "    Parameters:\n",
    "        new_paths: paths to train and test\n",
    "        path: where to get the reference dataset\n",
    "        list_airbus: list of Airbus aircraft types, e.g. ['A320', 'A330'] \n",
    "        list_boeing: list of Boeing aircraft types, e.g. ['737', '747'] \n",
    "        split_limit: % of images to use as train set\n",
    "        s: random seed\n",
    "\n",
    "    \"\"\"\n",
    "  \n",
    "    list_planes = [list_airbus, list_boeing]\n",
    "    for picts in list_planes:\n",
    "        if picts == list_airbus:\n",
    "            man = 'Airbus'\n",
    "        if picts == list_boeing:\n",
    "            man = 'Boeing'\n",
    "        \n",
    "        shutil.rmtree(new_paths[0] + '/' + man, ignore_errors = True)\n",
    "        os.makedirs(new_paths[0] + '/' + man)\n",
    "        \n",
    "        shutil.rmtree(new_paths[1] + '/' + man, ignore_errors = True)\n",
    "        os.makedirs(new_paths[1]+ '/' + man)\n",
    "        \n",
    "        random.seed(a = s)\n",
    "        random.shuffle(picts)\n",
    "        \n",
    "        print(new_paths[0] + '/' + man)\n",
    "\n",
    "        for pict in picts[:int(split_limit*len(picts))]:\n",
    "            copyfile(seatguru_path + pict, new_paths[0] + '/' + man + '/' +  pict)\n",
    "        for pict in picts[int(split_limit*len(picts)):]:\n",
    "            copyfile(seatguru_path + pict, new_paths[1] + '/' + man + '/' +  pict)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airliners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs_airliners(airliners_path, list_planes, man, split_limit, s = 8):\n",
    "    \n",
    "    for plane in list_planes:\n",
    "        os.makedirs(new_paths[0] + '/' + plane)\n",
    "        os.makedirs(new_paths[1] + '/' + plane)\n",
    "        \n",
    "        picts = os.listdir(airliners_path + '/' + man + '/' + plane)\n",
    "        random.seed(a=s)\n",
    "        random.shuffle(picts)\n",
    "        \n",
    "        for pict in picts[:int(split_limit * len(picts))]:\n",
    "            copyfile(airliners_path + '/' + man + '/' + plane + '/' + pict, \n",
    "                     new_paths[0] + '/' + plane + '/' + pict)\n",
    "            \n",
    "        for pict in picts[int(split_limit * len(picts)):]:\n",
    "            copyfile(airliners_path + '/' + man + '/' + plane + '/' + pict, \n",
    "                     new_paths[1] + '/' + plane + '/' + pict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_train_test_airliners(airliners_path, new_paths, \n",
    "                             airbus_planes = ['A320', 'A321', 'A350', 'A330'], \n",
    "                             boeing_planes = ['737', '747', '757', '777'], \n",
    "                             split_limit = .7, s = 8):\n",
    "    \n",
    "    for i in range(2): \n",
    "        os.makedirs(new_paths[i], exist_ok = True)\n",
    "        for fd in os.listdir(new_paths[i]):\n",
    "            shutil.rmtree(new_paths[i] + '/' + fd, ignore_errors=True)\n",
    "            \n",
    "    create_dirs_airliners(airliners_path, airbus_planes, 'Airbus', split_limit, s)\n",
    "    create_dirs_airliners(airliners_path, boeing_planes, 'Boeing', split_limit, s)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_hack(new_paths, hackathon_path, airbus_planes = ['A320', 'A330', 'A350', 'A380'],\n",
    "                          del_path : bool = True, split_limit = .7, s = 8):\n",
    "   \n",
    "    for plane in airbus_planes:\n",
    "        \n",
    "        if del_path == True:\n",
    "            shutil.rmtree(new_paths[0] + '/' + plane, ignore_errors=True)\n",
    "            os.makedirs(new_paths[0] + '/' + plane)\n",
    "            shutil.rmtree(new_paths[1] + '/' + plane, ignore_errors=True)\n",
    "            os.makedirs(new_paths[1] + '/' + plane)\n",
    "        else : # old path is not delete, mix with Seatguru\n",
    "            os.makedirs(new_paths[0] + '/' + plane, exist_ok = True)\n",
    "            os.makedirs(new_paths[1] + '/' + plane, exist_ok = True)\n",
    "        \n",
    "        try : \n",
    "            picts = os.listdir(hackathon_path + plane)\n",
    "            picts = [pic for pic in picts if pic[-4:]=='.jpg']\n",
    "            random.seed(a = s)\n",
    "            random.shuffle(picts)\n",
    "\n",
    "            for pict in picts[:int(split_limit*len(picts))]:\n",
    "                copyfile(hackathon_path + plane + '/' + pict, new_paths[0] + '/' + plane + '/' + pict)\n",
    "            for pict in picts[int(split_limit*len(picts)):]:\n",
    "                copyfile(hackathon_path + plane + '/' + pict, new_paths[1] + '/' + plane + '/' + pict)\n",
    "        except :\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_classes(path_mod, mod_name, train_generator, model):\n",
    "    \n",
    "    shutil.rmtree(path_mod + mod_name, ignore_errors = True)\n",
    "    os.makedirs(path_mod + mod_name)\n",
    "    label_map = (train_generator.class_indices)\n",
    "    with open(path_mod + mod_name + '/' + 'model_' + mod_name + '.pkl', \"wb\") as f:\n",
    "        pickle.dump(label_map, f)\n",
    "    model.save(path_mod + mod_name + '/' + 'model_'+ mod_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files_model(path_mod, mod_name):\n",
    "    model = load_model(path_mod + mod_name + '/' + 'model_'+ mod_name + '.h5')\n",
    "    with open(path_mod + mod_name + '/' + 'model_' + mod_name + '.pkl', \"rb\") as f:\n",
    "        dic_class = pickle.load(f)\n",
    "    return model, dic_class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
