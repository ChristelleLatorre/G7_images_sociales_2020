{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "created on: Wed Jan 08 10:05:38 2020\n",
    "Group 7\n",
    "@author: L.D., C.T.D., C.L."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization of hyperparameters using Talos\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook requiers the installation of talos.\n",
    "\n",
    "\n",
    "It aims to present a method to find the best hyperparameters in deep learning, equivalent to a gridSearch in Machine Learning.\n",
    "The output is a CSV file summarizing for each combination :  \n",
    "round_epochs,val_loss,val_accuracy,loss,accuracy\n",
    "The last columns indicate the hyperparameters values(in this notebook, activation and conv_dropout).\n",
    "The resulting CSV can be found in the same folder as this notebook.\n",
    "\n",
    "By lack of time, this method has not been used on the models at the end of the project. \n",
    "However, with more time, it could be interesting to increase the accuracy of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting talos\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/df/c352679af3259829dafa7d55f2d3e9fca201c848351cb3c841a062df001c/talos-0.6.3.tar.gz\n",
      "Collecting wrangle (from talos)\n",
      "  Downloading https://files.pythonhosted.org/packages/85/35/bc729e377417613f2d062a890faea5d649ef1a554df21499e9c3a4a5501a/wrangle-0.6.7.tar.gz\n",
      "Requirement already satisfied: numpy in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from talos) (1.17.2)\n",
      "Requirement already satisfied: pandas in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from talos) (0.25.1)\n",
      "Requirement already satisfied: keras in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from talos) (2.3.1)\n",
      "Collecting astetik (from talos)\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/ba/f8622951da73d9b47b45bb847112c388651f9c6e413e712954f260301d9f/astetik-1.9.9.tar.gz\n",
      "Collecting sklearn (from talos)\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Requirement already satisfied: tqdm in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from talos) (4.36.1)\n",
      "Collecting chances (from talos)\n",
      "  Downloading https://files.pythonhosted.org/packages/fa/d8/d61112d7476dc3074b855f1edd8556cde9b49b7106853f0b060109dd4c82/chances-0.1.9.tar.gz\n",
      "Collecting kerasplotlib (from talos)\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/2e/b8628bfef6a817da9be863f650cf67187676b10d27d94b23f248da35d2b4/kerasplotlib-0.1.4.tar.gz\n",
      "Requirement already satisfied: requests in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from talos) (2.22.0)\n",
      "Collecting scipy==1.2 (from wrangle->talos)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/39/066ecde98f373430bf7a39a02d91c7075b01ef4fc928456e8e31577342d6/scipy-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (26.6MB)\n",
      "\u001b[K     |████████████████████████████████| 26.6MB 6.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: statsmodels in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from wrangle->talos) (0.10.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from pandas->talos) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from pandas->talos) (2.8.0)\n",
      "Requirement already satisfied: pyyaml in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from keras->talos) (5.1.2)\n",
      "Requirement already satisfied: h5py in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from keras->talos) (2.9.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from keras->talos) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from keras->talos) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from keras->talos) (1.0.8)\n",
      "Collecting geonamescache (from astetik->talos)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c1/efb823270c8526b2f4f3eb8c804c5a0a55277267ad2312f5eb47bd9cc370/geonamescache-1.1.0-py3-none-any.whl (830kB)\n",
      "\u001b[K     |████████████████████████████████| 839kB 14.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from sklearn->talos) (0.21.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from requests->talos) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from requests->talos) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from requests->talos) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from requests->talos) (2019.9.11)\n",
      "Requirement already satisfied: patsy>=0.4.0 in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from statsmodels->wrangle->talos) (0.5.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/sid2019-18/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn->talos) (0.13.2)\n",
      "Building wheels for collected packages: talos, wrangle, astetik, sklearn, chances, kerasplotlib\n",
      "  Building wheel for talos (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for talos: filename=talos-0.6.3-cp37-none-any.whl size=49626 sha256=139a352f29b98f9e0d4ebb53d72ff2798515b1262a16d3d443c4489a46c25452\n",
      "  Stored in directory: /home/sid2019-18/.cache/pip/wheels/bb/d7/6b/86fd8b1fc7cfbd2c54796412f86efb5fb6a3a5c734014f6a66\n",
      "  Building wheel for wrangle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrangle: filename=wrangle-0.6.7-cp37-none-any.whl size=49895 sha256=43af8090268828324f0888ff88f63c315058ea0a6756f0ff0c82b561ef9a3230\n",
      "  Stored in directory: /home/sid2019-18/.cache/pip/wheels/bf/1b/50/d0403ce6ef269e364894da7b50db68db14c4ac62c577561e2d\n",
      "  Building wheel for astetik (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for astetik: filename=astetik-1.9.9-cp37-none-any.whl size=56960 sha256=b98140ec7c62f6bc51313fc2bfe33e44950ec3f4e46a1e128aff981da8a0a384\n",
      "  Stored in directory: /home/sid2019-18/.cache/pip/wheels/ae/70/21/c475cd079ec401dd6e1b9b1d42b4c38554ce12679bfb214aad\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=226f3c7edbec2f3dba50e6e7775fd22c1fecc6677839f3b1a8f4e3bbabe8a073\n",
      "  Stored in directory: /home/sid2019-18/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "  Building wheel for chances (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for chances: filename=chances-0.1.9-cp37-none-any.whl size=41608 sha256=ca08a41b6a5071f9af145c67ae9a6d9d0ff7f6cc335308f38fb1454db37a4970\n",
      "  Stored in directory: /home/sid2019-18/.cache/pip/wheels/75/33/46/c871b94249bd57d17797d049b3dff8e3a09c315afb67eb14c6\n",
      "  Building wheel for kerasplotlib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kerasplotlib: filename=kerasplotlib-0.1.4-cp37-none-any.whl size=3580 sha256=2619a30428cfbc0f46a7f42c7b5e2925e057ca4187c178f5d1ba6f32df936398\n",
      "  Stored in directory: /home/sid2019-18/.cache/pip/wheels/36/6b/4c/e1fc6d7d8811940fbea1147b1519c7baa6933e4baeff904433\n",
      "Successfully built talos wrangle astetik sklearn chances kerasplotlib\n",
      "Installing collected packages: scipy, sklearn, wrangle, geonamescache, astetik, chances, kerasplotlib, talos\n",
      "  Found existing installation: scipy 1.3.1\n",
      "    Uninstalling scipy-1.3.1:\n",
      "      Successfully uninstalled scipy-1.3.1\n",
      "Successfully installed astetik-1.9.9 chances-0.1.9 geonamescache-1.1.0 kerasplotlib-0.1.4 scipy-1.2.0 sklearn-0.0 talos-0.6.3 wrangle-0.6.7\n"
     ]
    }
   ],
   "source": [
    "! pip install talos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from keras.models import load_model\n",
    "\n",
    "# keras : librairie de deep learning\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, InputLayer, ReLU, Dense, Flatten, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import talos as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = './../'\n",
    "scrap_path = project_path + 'Scraping/'\n",
    "airliners_path = scrap_path + 'Airliners/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading(path = None, shape = (500,500), proba_train = 0.6, proba_test = 0.7):\n",
    "    data_train = []\n",
    "    data_test = []\n",
    "    for i in tqdm(os.listdir(path)):\n",
    "        if i[-3:] == 'jpg':\n",
    "            rand = np.random.random()\n",
    "            if rand <= proba_train:\n",
    "                img = Image.open(path + i)\n",
    "                data_train.append(np.mean(np.array(img.resize(shape, Image.BILINEAR)), axis=2))\n",
    "            \n",
    "            elif rand >= proba_test:\n",
    "                img = Image.open(path + i)\n",
    "                data_test.append(np.mean(np.array(img.resize(shape, Image.BILINEAR)), axis=2))\n",
    "            \n",
    "    return np.array(data_train), np.array(data_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168dfc8ddba144fca48e50445e4a57b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "A320_train, A320_test = reading(airliners_path + 'Airbus/A320/', (256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617, 256, 256)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A320_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269, 256, 256)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A320_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592c376616ba45e1995e70f8f5ec448c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079b670f6ef74f19a7ebdb348f720d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbdccc7ea78473eb7d0085896070c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44526510697441e89f738c65458dcc4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16dd8beeeba405699b8500a837bf387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450206bf0f574408be58df496c9d2de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230cb19485284d868606b3901da26613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "A330_train, A330_test = reading(airliners_path + 'Airbus/A330/', (256,256))\n",
    "A350_train, A350_test = reading(airliners_path + \"Airbus/A350/\", (256,256))\n",
    "A380_train, A380_test = reading(airliners_path + \"Airbus/A380/\", (256,256))\n",
    "Boeing737_train, Boeing737_test = reading(airliners_path + \"Boeing/737/\", (256,256))\n",
    "Boeing747_train, Boeing747_test = reading(airliners_path + \"Boeing/747/\", (256,256))\n",
    "Boeing767_train, Boeing767_test = reading(airliners_path + \"Boeing/767/\", (256,256))\n",
    "Boeing777_train, Boeing777_test = reading(airliners_path + \"Boeing/777/\", (256,256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "yBoeing_train  = np.repeat('Boeing', len(Boeing777_train)+len(Boeing767_train)+ len(Boeing747_train) + len(Boeing737_train))\n",
    "yAirbus_train = np.repeat('Airbus', len(A380_train) + len(A350_train) + len(A330_train)+ len(A320_train))\n",
    "\n",
    "yBoeing_test  = np.repeat('Boeing', len(Boeing777_test)+len(Boeing767_test)+ len(Boeing747_test) + len(Boeing737_test))\n",
    "yAirbus_test = np.repeat('Airbus', len(A380_test) + len(A350_test) + len(A330_test)+ len(A320_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = np.concatenate((yAirbus_train, yBoeing_train))\n",
    "ytrain = pd.get_dummies(pd.Series(ytrain)).values\n",
    "\n",
    "ytest = np.concatenate((yAirbus_test, yBoeing_test))\n",
    "ytest = pd.get_dummies(pd.Series(ytest)).values\n",
    "\n",
    "data_train = np.concatenate((A320_train,A330_train,A350_train,A380_train,\n",
    "                             Boeing777_train,Boeing767_train,Boeing747_train,Boeing737_train))\n",
    "\n",
    "data_test = np.concatenate((A320_test,A330_test,A350_test, A380_test,\n",
    "                            Boeing777_test,Boeing767_test,Boeing747_test,Boeing737_test))\n",
    "\n",
    "data_train = np.reshape(data_train, (data_train.shape[0], 256, 256, 1))\n",
    "\n",
    "data_test = np.reshape(data_test, (data_test.shape[0], 256, 256, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4815, 2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2378, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4815, 256, 256, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(ytrain.shape[0])\n",
    "np.random.shuffle(arr)\n",
    "\n",
    "ytrain = ytrain[arr]\n",
    "data_train = data_train[arr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(ytest.shape[0])\n",
    "np.random.shuffle(arr)\n",
    "\n",
    "ytest = ytest[arr]\n",
    "data_test = data_test[arr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(data_train, ytrain, data_test, ytest,  para, input_shape = (256,256,1), nb_couches = 5,\n",
    "                 nb_neur = 4, kernel = (3, 3), pool = (2, 2),  nb_classes = ytrain.shape[1]):\n",
    "    \n",
    "    conv_dropout = para['conv_dropout'] \n",
    "     \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "    \n",
    "    for i in range(nb_couches):\n",
    "        model.add(Conv2D(2**(nb_neur + i), kernel_size=kernel, activation = para['activation']))\n",
    "        model.add(Dropout(conv_dropout))\n",
    "     \n",
    "        model.add(Conv2D(2**(nb_neur + i), kernel_size=kernel, activation = para['activation']))\n",
    "        model.add(Dropout(conv_dropout))\n",
    "       \n",
    "        model.add(MaxPooling2D(pool_size = pool))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(nb_classes, activation = 'softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "    \n",
    "    out = model.fit(\n",
    "        data_train, ytrain, epochs=10, batch_size=32, \n",
    "        verbose=0,\n",
    "        validation_data=[data_test, ytest])\n",
    "   \n",
    "    return out, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\n",
      "\n",
      " 25%|████████████████████                                                            | 1/4 [50:17<2:30:52, 3017.56s/it]\n",
      "\n",
      " 50%|███████████████████████████████████████                                       | 2/4 [2:40:32<2:16:33, 4096.64s/it]\n",
      "\n",
      " 75%|█████████████████████████████████████████████████████████                   | 3/4 [15:06:15<4:31:30, 16290.73s/it]\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4/4 [17:06:24<00:00, 15396.03s/it]\n"
     ]
    }
   ],
   "source": [
    "para = {'activation': ['relu', 'softmax'],\n",
    "        'conv_dropout': [0.1, 0.2]\n",
    "}\n",
    "scan_results = ta.Scan(data_train, ytrain, para, create_model, 'talos_V0', x_val = data_test, y_val = ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
