{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on Mon Jan 13 16:00:47 2020\n",
    "<br>\n",
    "Group 7\n",
    "<br>\n",
    "@authors : G.H.\n",
    "<h1>Group 7 - Images sociales<span class=\"tocSkip\"></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Environment\" data-toc-modified-id=\"Environment-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Environment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Libraries\" data-toc-modified-id=\"Libraries-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Libraries</a></span></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Parameters</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Functions</a></span></li></ul></li><li><span><a href=\"#Train-test-split-and-read-images\" data-toc-modified-id=\"Train-test-split-and-read-images-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Train-test split and read images</a></span></li><li><span><a href=\"#Build,-save,-and-train-model\" data-toc-modified-id=\"Build,-save,-and-train-model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Build, save, and train model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook trains a model to predict Airbus aircraft types on images representing an aircraft interior. The images used for training come from Seatguru social media.\n",
    "\n",
    "**Pre-processing**<span class=\"tocSkip\"></span><br>\n",
    "By reading and filtering the CSV file that contains the labels (Int, Ext, Ext-Int, Meal), we get the list of Interior labelled images. Then, the images are copied to directories (one per desired aircraft type), and split into train and test sets. If the data augmentation option is set to `True`, the train set will be enriched with new images (obtained by cropping / (de)zooming / rotating / flipping existing images).\n",
    "\n",
    "**Model**<span class=\"tocSkip\"></span><br>\n",
    "We get weights from VGG16 pre-trained model, and add some layers (Conv2D, ReLU, MaxPooling2D, Flatten, and Dense) to predict the target classes (e.g.: 3 classes could be A320, A350, and A380).\n",
    "\n",
    "**Out**<span class=\"tocSkip\"></span><br>\n",
    "After training, a folder is created in `Models` repository, containing the model in `h5` format, along with the corresponding labels stored in a `pickle` dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "To ensure a proper functioning of this code file, `python 3.6` or later version is required.\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T15:19:11.728311Z",
     "start_time": "2020-01-09T15:19:06.196795Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, InputLayer, ReLU, AveragePooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%load_ext watermark\n",
    "%watermark -p keras,tensorflow,PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = './../'\n",
    "seatguru_path = project_path + 'Interpromo2020/All Data/ANALYSE IMAGE/IMG SEATGURU/'\n",
    "stats_path = project_path + 'ImagesStats/'\n",
    "new_path_train = project_path + 'G7_SEATGURU/Int/data_train'\n",
    "new_path_val = project_path + 'G7_SEATGURU/Int/data_test'\n",
    "new_paths = [new_path_train, new_path_val]\n",
    "model_name = 'Int_man_F_2'\n",
    "\n",
    "# Images parameters\n",
    "size = (224, 224)\n",
    "greys = False\n",
    "\n",
    "\n",
    "# Number of classes to predict\n",
    "nb_types = 2  # Airbus, Boeing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run g7_functions_for_models_V2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split and read images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read SEATGURU annotated CSV\n",
    "df_seat_annot = pd.read_csv(stats_path + 'g7_SEATGURU_annotate.csv', sep=';')\n",
    "\n",
    "# Get Airbus and Boeing images names for Interior view\n",
    "df_airbus = df_seat_annot[df_seat_annot['aircraft_manufacturer'] == 'Airbus']\n",
    "list_airbus = df_airbus[df_airbus['view'] == 'Int']['name'].tolist()\n",
    "\n",
    "df_boeing = df_seat_annot[df_seat_annot['aircraft_manufacturer'] == 'Boeing']\n",
    "list_boeing = df_boeing[df_boeing['view'] == 'Int']['name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../G7_SEATGURU/Int/data_train/Airbus\n",
      "./../G7_SEATGURU/Int/data_train/Boeing\n"
     ]
    }
   ],
   "source": [
    "# Create train and test sets\n",
    "split_train_test_seatguru_man(new_paths, seatguru_path, list_airbus, list_boeing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1123 images belonging to 2 classes.\n",
      "Found 482 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image data generator\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = train_datagen.flow_from_directory(new_paths[0],\n",
    "                                                    target_size=size,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "\n",
    "test_generator = train_datagen.flow_from_directory(new_paths[1],\n",
    "                                                   target_size=size,\n",
    "                                                   color_mode='rgb',\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build, save, and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T09:22:00.420098Z",
     "start_time": "2020-01-10T09:21:59.487724Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 40,937,794\n",
      "Trainable params: 26,220,034\n",
      "Non-trainable params: 14,717,760\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the base pre-trained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(size[0], size[1], 1 if greys else 3))\n",
    "x = base_model.output\n",
    "\n",
    "# Add layers\n",
    "'''x = Conv2D(256, kernel_size=(3, 3))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(256, kernel_size=(3, 3))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)'''\n",
    "\n",
    "x = Flatten()(x)  # vector\n",
    "\n",
    "# Fully-connected layer\n",
    "x = Dense(1024)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Dense(512)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "# Output layer to predict the class\n",
    "predictions = Dense(nb_types, activation = 'softmax')(x)\n",
    "\n",
    "# Model to be trained\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Don't retrain pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce learning rate when a metric has stopped improving\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy',  # chosen metric\n",
    "                              patience=2,  # number of epochs\n",
    "                              verbose=1,\n",
    "                              factor=0.5,\n",
    "                              min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35/35 [==============================] - 508s 15s/step - loss: 1.1055 - accuracy: 0.5160 - val_loss: 0.0148 - val_accuracy: 0.5830\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 493s 14s/step - loss: 0.2370 - accuracy: 0.9120 - val_loss: 0.0319 - val_accuracy: 0.6162\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 2313s 66s/step - loss: 0.0720 - accuracy: 0.9881 - val_loss: 0.7488 - val_accuracy: 0.5913\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 497s 14s/step - loss: 0.0250 - accuracy: 0.9982 - val_loss: 0.3259 - val_accuracy: 0.6141\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 553s 16s/step - loss: 0.0209 - accuracy: 0.9963 - val_loss: 0.5613 - val_accuracy: 0.6245\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 515s 15s/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.0432 - val_accuracy: 0.6307\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 503s 14s/step - loss: 0.0183 - accuracy: 0.9962 - val_loss: 1.4244 - val_accuracy: 0.5913\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 389s 11s/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.6100\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 262s 7s/step - loss: 0.0531 - accuracy: 0.9945 - val_loss: 2.0708 - val_accuracy: 0.6162\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 263s 8s/step - loss: 0.0163 - accuracy: 0.9991 - val_loss: 0.5875 - val_accuracy: 0.6141\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f66053e2b90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "step_size_train = train_generator.n // train_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=step_size_train,\n",
    "                    epochs=10,\n",
    "                    validation_data=test_generator,\n",
    "                    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and labels\n",
    "os.makedirs(project_path + 'Models/' + model_name + '/', exist_ok=True)\n",
    "save_model_classes(project_path + 'Models/',\n",
    "                   model_name, train_generator, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "294px",
    "left": "1070px",
    "right": "30px",
    "top": "120px",
    "width": "340px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
