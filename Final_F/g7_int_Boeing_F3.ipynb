{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on Fri Jan 13 14:20:37 2020\n",
    "<br>\n",
    "Group 7\n",
    "<br>\n",
    "@authors: E.G., C.L.\n",
    "<h1>Group 7 - Images sociales<span class=\"tocSkip\"></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Environment\" data-toc-modified-id=\"Environment-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Environment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Libraries\" data-toc-modified-id=\"Libraries-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Libraries</a></span></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Parameters</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Functions</a></span></li></ul></li><li><span><a href=\"#Pre-processing\" data-toc-modified-id=\"Pre-processing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Pre-processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-directories\" data-toc-modified-id=\"Create-directories-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Create directories</a></span></li><li><span><a href=\"#Train-test-split-and-read-images\" data-toc-modified-id=\"Train-test-split-and-read-images-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Train-test split and read images</a></span></li></ul></li><li><span><a href=\"#Build,-save,-and-train-model\" data-toc-modified-id=\"Build,-save,-and-train-model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Build, save, and train model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook trains a model to predict Boeing aircraft types on images representing an aircraft interior. The images used for training come from Seatguru social media.\n",
    "\n",
    "**Pre-processing**<span class=\"tocSkip\"></span><br>\n",
    "By reading and filtering the CSV file that contains the labels (Int, Ext, Ext-Int, Meal), we get the list of Interior labelled images. Then, the images are copied to directories (one per desired aircraft type), and split into train and test sets. If the data augmentation option is set to `True`, the train set will be enriched with new images (obtained by cropping / (de)zooming / rotating / flipping existing images).\n",
    "\n",
    "**Model**<span class=\"tocSkip\"></span><br>\n",
    "We get weights from VGG16 pre-trained model, and add some layers (Conv2D, ReLU, MaxPooling2D, Flatten, and Dense) to predict the target classes (e.g.: 4 classes could be 737, 747, 757, and 777).\n",
    "\n",
    "**Out**<span class=\"tocSkip\"></span><br>\n",
    "After training, a folder is created in `Models` repository, containing the model in `h5` format, along with the corresponding labels stored in a `pickle` dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "To ensure a proper functioning of this code file, `python 3.6` or later version is required.\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T15:19:11.728311Z",
     "start_time": "2020-01-09T15:19:06.196795Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, InputLayer, ReLU, AveragePooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%load_ext watermark\n",
    "%watermark -p keras,tensorflow,PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = './../'\n",
    "seatguru_path = project_path + 'Interpromo2020/All Data/ANALYSE IMAGE/IMG SEATGURU/'\n",
    "stats_path = project_path + 'ImagesStats/'\n",
    "\n",
    "model_name = 'Int_Boeing_F3'\n",
    "\n",
    "# Classes to predict\n",
    "boeing_planes = ['737', '747', '757', '767', '777', '787']\n",
    "nb_types = len(boeing_planes)\n",
    "\n",
    "# Images parameters\n",
    "size = (224, 224)\n",
    "greys = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run g7_functions_for_models_V2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "## Create directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../G7_SEATGURU/Int/Boeing/data_train ./../G7_SEATGURU/Int/Boeing/data_test\n",
      "./../G7_SEATGURU/Int/Boeing/737\n",
      "737: 201 images\n",
      "./../G7_SEATGURU/Int/Boeing/747\n",
      "747: 52 images\n",
      "./../G7_SEATGURU/Int/Boeing/757\n",
      "757: 44 images\n",
      "./../G7_SEATGURU/Int/Boeing/767\n",
      "767: 114 images\n",
      "./../G7_SEATGURU/Int/Boeing/777\n",
      "777: 279 images\n",
      "./../G7_SEATGURU/Int/Boeing/787\n",
      "787: 160 images\n"
     ]
    }
   ],
   "source": [
    "# Read SEATGURU annotated CSV\n",
    "df_seat_annot = pd.read_csv(stats_path + 'g7_SEATGURU_annotate.csv', sep=';', engine='python',\n",
    "                            index_col=None, encoding='utf-8')\n",
    "\n",
    "# Paths where to create aircraft types folders\n",
    "crea_path = project_path + 'G7_SEATGURU/Int/Boeing/'\n",
    "new_paths = [crea_path + 'data_train', crea_path + 'data_test']\n",
    "print(new_paths[0], new_paths[1])\n",
    "\n",
    "# Create a directory for each class\n",
    "create_dirs_seatguru_type(df_seat_annot, project_path, seatguru_path, crea_path, aircraft_types=boeing_planes,\n",
    "                          view='Int', man='Boeing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split and read images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test\n",
    "split_train_test_seatguru_type(\n",
    "    new_paths=new_paths, path=crea_path, aircraft_types=boeing_planes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T15:26:28.959798Z",
     "start_time": "2020-01-09T15:26:19.480789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 592 images belonging to 6 classes.\n",
      "Found 258 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image data generator\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = datagen.flow_from_directory(new_paths[0],\n",
    "                                              target_size=size,\n",
    "                                              color_mode='rgb',\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle=True)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(new_paths[1],\n",
    "                                             target_size=size,\n",
    "                                             color_mode='rgb',\n",
    "                                             batch_size=32,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build, save, and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T09:22:00.420098Z",
     "start_time": "2020-01-10T09:21:59.487724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 17,283,910\n",
      "Trainable params: 2,565,126\n",
      "Non-trainable params: 14,718,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the base pre-trained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False,\n",
    "                   input_shape=(size[0], size[1], 1 if greys else 3))\n",
    "x = base_model.output\n",
    "\n",
    "# Add layers\n",
    "x = Conv2D(256, kernel_size=(3, 3))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(256, kernel_size=(3, 3))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)  # vector\n",
    "\n",
    "x = Dense(1024)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Dense(512)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "# Last layer used to predict our classes\n",
    "# Dense has the same number of neurons as the number of classes to predict\n",
    "predictions = Dense(nb_types, activation='softmax')(x)\n",
    "\n",
    "# Model to be trained\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Don't retrain pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model (should be done after setting layers to non-trainable)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce learning rate when a metric has stopped improving\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy',  # chosen metric\n",
    "                              patience=2,  # number of epochs\n",
    "                              verbose=1,\n",
    "                              factor=0.5,\n",
    "                              min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 373s 21s/step - loss: 2.0721 - accuracy: 0.3143 - val_loss: 0.8765 - val_accuracy: 0.2403\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 268s 15s/step - loss: 0.7251 - accuracy: 0.7656 - val_loss: 5.4196 - val_accuracy: 0.2558\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 256s 14s/step - loss: 0.1739 - accuracy: 0.9559 - val_loss: 4.8458 - val_accuracy: 0.2907\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 264s 15s/step - loss: 0.0399 - accuracy: 0.9964 - val_loss: 3.9106 - val_accuracy: 0.3333\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 254s 14s/step - loss: 0.0160 - accuracy: 0.9964 - val_loss: 2.5392 - val_accuracy: 0.3721\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 255s 14s/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.3194 - val_accuracy: 0.3643\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 250s 14s/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.4856 - val_accuracy: 0.3605\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 254s 14s/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.4667 - val_accuracy: 0.3798\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 23691s 1316s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.7506 - val_accuracy: 0.3837\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 296s 16s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.3837\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 260s 14s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.6349 - val_accuracy: 0.4031\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 266s 15s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.9696 - val_accuracy: 0.3876\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 263s 15s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.3440 - val_accuracy: 0.3953\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 254s 14s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.3898 - val_accuracy: 0.3953\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 258s 14s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0299 - val_accuracy: 0.3915\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 253s 14s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.8158 - val_accuracy: 0.3953\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 250s 14s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.2117 - val_accuracy: 0.3915\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 249s 14s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.1755 - val_accuracy: 0.3953\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 252s 14s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0873 - val_accuracy: 0.3915\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 260s 14s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4595 - val_accuracy: 0.3915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6db489ea50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "step_size_train = train_generator.n // train_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=step_size_train,\n",
    "                    epochs=20,\n",
    "                    validation_data=test_generator,\n",
    "                    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and labels\n",
    "os.makedirs(project_path + 'Models/' + model_name + '/', exist_ok=True)\n",
    "save_model_classes(project_path + 'Models/',\n",
    "                   model_name, train_generator, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "294px",
    "left": "1070px",
    "right": "30px",
    "top": "120px",
    "width": "340px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
