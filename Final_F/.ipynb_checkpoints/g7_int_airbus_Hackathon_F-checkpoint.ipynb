{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on Fri Jan 10 11:06:30 2020\n",
    "<br>\n",
    "Group 7\n",
    "<br>\n",
    "@author: E.G.\n",
    "\n",
    "<h1>Group 7 - Images sociales<span class=\"tocSkip\"></span>\n",
    "    \n",
    "<br>    \n",
    "<center>Airbus Interiors - aircraft types model - Hackathon<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Environment\" data-toc-modified-id=\"Environment-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Environment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Libraries\" data-toc-modified-id=\"Libraries-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Libraries</a></span></li><li><span><a href=\"#Parameters\" data-toc-modified-id=\"Parameters-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Parameters</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Functions</a></span></li></ul></li><li><span><a href=\"#Train-test-split-and-read-images\" data-toc-modified-id=\"Train-test-split-and-read-images-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Train-test split and read images</a></span></li><li><span><a href=\"#Build,-save,-and-train-model\" data-toc-modified-id=\"Build,-save,-and-train-model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Build, save, and train model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook trains a model to predict Airbus aircraft types on images representing an aircraft interior. The images used for training come from Hackathon data (\"clean\" images of Airbus aircraft interiors).\n",
    "\n",
    "**Pre-processing**<span class=\"tocSkip\"></span><br>\n",
    "By reading and filtering the CSV file that contains the labels (Int, Ext, Ext-Int, Meal), we get the list of Interior labelled images. Then, the images are copied to directories (one per desired aircraft type), and split into train and test sets. If the data augmentation option is set to `True`, the train set will be enriched with new images (obtained by cropping / (de)zooming / rotating / flipping existing images).\n",
    "\n",
    "**Model**<span class=\"tocSkip\"></span><br>\n",
    "We get weights from VGG16 pre-trained model, and add some layers (Conv2D, ReLU, MaxPooling2D, Flatten, and Dense) to predict the target classes (e.g.: 3 classes could be A320, A350, and A380).\n",
    "\n",
    "**Out**<span class=\"tocSkip\"></span><br>\n",
    "After training, a folder is created in `Models` repository, containing the model in `h5` format, along with the corresponding labels stored in a `pickle` dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "To ensure a proper functioning of this code file, `python 3.6` or later version is required.\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T15:19:11.728311Z",
     "start_time": "2020-01-09T15:19:06.196795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, InputLayer, ReLU, AveragePooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras 2.3.1\n",
      "tensorflow 1.13.1\n",
      "PIL 6.2.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p keras,tensorflow,PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = './../'\n",
    "hackathon_path = project_path + 'InputsHackathon/'\n",
    "new_path_train = project_path + 'Split_data/Hackathon/Int/data_train'\n",
    "new_path_val = project_path + 'Split_data/Hackathon/Int/data_val'\n",
    "new_paths = [new_path_train, new_path_val]\n",
    "\n",
    "model_name = 'Int_Airbus_Hackathon_F'\n",
    "\n",
    "# Classes to predict\n",
    "airbus_planes = ['A320', 'A330', 'A350', 'A380']\n",
    "nb_types = len(airbus_planes)\n",
    "\n",
    "# Images parameters\n",
    "size = (224, 224)\n",
    "greys = False\n",
    "apply_data_augmentation = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run g7_functions_for_models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split and read images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_test_hack(new_paths, hackathon_path,\n",
    "                      aircraft_types=airbus_planes, split_limit=.7, s=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option: use data augmentation to enrich your train set\n",
    "if apply_data_augmentation:\n",
    "    %run g7_data_augmentation.py\n",
    "    data_augmentation(train_path=new_paths[0], shape=size, save_format='jpeg', nb_win=2, coef_gen=2,\n",
    "                      greys=False, rotation_range=20, shear_range=.2, zoom_range=.15, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T15:26:28.959798Z",
     "start_time": "2020-01-09T15:26:19.480789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 802 images belonging to 4 classes.\n",
      "Found 346 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image data generator\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = datagen.flow_from_directory(new_paths[0],\n",
    "                                              target_size=(224, 224),\n",
    "                                              color_mode='rgb',\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle=True)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(new_paths[1],\n",
    "                                             target_size=(224, 224),\n",
    "                                             color_mode='rgb',\n",
    "                                             batch_size=32,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build, save, and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T09:22:00.420098Z",
     "start_time": "2020-01-10T09:21:59.487724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 17,282,884\n",
      "Trainable params: 2,564,100\n",
      "Non-trainable params: 14,718,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the base pre-trained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False,\n",
    "                   input_shape=(size[0], size[1], 1 if greys else 3))\n",
    "x = base_model.output\n",
    "\n",
    "# Add layers\n",
    "x = Conv2D(256, kernel_size=(3, 3))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(256, kernel_size=(3, 3))(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)  # vector\n",
    "\n",
    "x = Dense(1024)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Dense(512)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "# Last layer used to predict our classes\n",
    "# Dense has the same number of neurons as the number of classes to predict\n",
    "predictions = Dense(nb_types, activation='softmax')(x)\n",
    "\n",
    "# Model to be trained\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Don't retrain pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model (should be done after setting layers to non-trainable)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce learning rate when a metric has stopped improving\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy',  # chosen metric\n",
    "                              patience=2,  # number of epochs\n",
    "                              verbose=1,\n",
    "                              factor=0.5,\n",
    "                              min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T09:46:07.626778Z",
     "start_time": "2020-01-10T09:27:13.063490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 572s 23s/step - loss: 1.4811 - accuracy: 0.4377 - val_loss: 2.6104 - val_accuracy: 0.4220\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 557s 22s/step - loss: 0.3923 - accuracy: 0.8610 - val_loss: 1.7984 - val_accuracy: 0.4191\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 541s 22s/step - loss: 0.1818 - accuracy: 0.9481 - val_loss: 1.1108 - val_accuracy: 0.5289\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 542s 22s/step - loss: 0.1498 - accuracy: 0.9753 - val_loss: 1.4813 - val_accuracy: 0.5607\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 559s 22s/step - loss: 0.1549 - accuracy: 0.9425 - val_loss: 3.1929 - val_accuracy: 0.5347\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 532s 21s/step - loss: 0.3347 - accuracy: 0.9378 - val_loss: 1.6106 - val_accuracy: 0.5607\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 548s 22s/step - loss: 0.1068 - accuracy: 0.9766 - val_loss: 1.5251 - val_accuracy: 0.6214\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 546s 22s/step - loss: 0.0787 - accuracy: 0.9753 - val_loss: 1.1407 - val_accuracy: 0.6792\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 547s 22s/step - loss: 0.0383 - accuracy: 0.9922 - val_loss: 1.3863 - val_accuracy: 0.6474\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 559s 22s/step - loss: 0.0195 - accuracy: 0.9975 - val_loss: 1.0948 - val_accuracy: 0.6792\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc5960a4410>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "step_size_train = train_generator.n // train_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=step_size_train,\n",
    "                    epochs=10,\n",
    "                    validation_data=test_generator,\n",
    "                    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and labels\n",
    "os.makedirs(project_path + 'Models/' + model_name + '/', exist_ok=True)\n",
    "save_model_classes(project_path + 'Models/',\n",
    "                   model_name, train_generator, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "294px",
    "left": "1070px",
    "right": "30px",
    "top": "120px",
    "width": "340px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
